

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hidden Markov Model &mdash; Pyro Tutorials 编译 1.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Latent Dirichlet Allocation" href="lda.html" />
    <link rel="prev" title="Causal Effect VAE" href="cevae.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro 模型介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Pyro 推断简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: Pyro 随机变分推断基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: 条件独立, 子采样和 Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Tensor shapes in Pyro</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">自定义 SVI 目标函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Pyro 模型中使用 PyTorch JIT Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: Pyro 中使用 Effect Handlers 编程手册</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vae.html">变分自编码器</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">贝叶斯回归- Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">贝叶斯回归-推断算法(Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">深马尔可夫模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">半监督 VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">随机波动率的 Levy 稳定分布模型</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributed:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting Black Box Variational Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Examples:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Causal Effect VAE</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hidden Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Latent Dirichlet Allocation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Deep Kernel Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Gaussian Process Time Series Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Sequential Monte Carlo Filtering</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials 编译</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Hidden Markov Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/hmm.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="hidden-markov-model">
<h1>Hidden Markov Model<a class="headerlink" href="#hidden-markov-model" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://github.com/pyro-ppl/pyro/blob/dev/examples/hmm.py">View hmm.py on github</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright (c) 2017-2019 Uber Technologies, Inc.</span>
<span class="c1"># SPDX-License-Identifier: Apache-2.0</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This example shows how to marginalize out discrete model variables in Pyro.</span>

<span class="sd">This combines Stochastic Variational Inference (SVI) with a</span>
<span class="sd">variable elimination algorithm, where we use enumeration to exactly</span>
<span class="sd">marginalize out some variables from the ELBO computation. We might</span>
<span class="sd">call the resulting algorithm collapsed SVI or collapsed SGVB (i.e</span>
<span class="sd">collapsed Stochastic Gradient Variational Bayes). In the case where</span>
<span class="sd">we exactly sum out all the latent variables (as is the case here),</span>
<span class="sd">this algorithm reduces to a form of gradient-based Maximum</span>
<span class="sd">Likelihood Estimation.</span>

<span class="sd">To marginalize out discrete variables ``x`` in Pyro&#39;s SVI:</span>

<span class="sd">1. Verify that the variable dependency structure in your model</span>
<span class="sd">    admits tractable inference, i.e. the dependency graph among</span>
<span class="sd">    enumerated variables should have narrow treewidth.</span>
<span class="sd">2. Annotate each target each such sample site in the model</span>
<span class="sd">    with ``infer={&quot;enumerate&quot;: &quot;parallel&quot;}``</span>
<span class="sd">3. Ensure your model can handle broadcasting of the sample values</span>
<span class="sd">    of those variables</span>
<span class="sd">4. Use the ``TraceEnum_ELBO`` loss inside Pyro&#39;s ``SVI``.</span>

<span class="sd">Note that empirical results for the models defined here can be found in</span>
<span class="sd">reference [1]. This paper also includes a description of the &quot;tensor</span>
<span class="sd">variable elimination&quot; algorithm that Pyro uses under the hood to</span>
<span class="sd">marginalize out discrete latent variables.</span>

<span class="sd">References</span>

<span class="sd">1. &quot;Tensor Variable Elimination for Plated Factor Graphs&quot;,</span>
<span class="sd">Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Justin Chiu,</span>
<span class="sd">Neeraj Pradhan, Alexander Rush, Noah Goodman. https://arxiv.org/abs/1902.03210</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">constraints</span>

<span class="kn">import</span> <span class="nn">dmm.polyphonic_data_loader</span> <span class="kn">as</span> <span class="nn">poly</span>
<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="kn">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">pyro</span> <span class="kn">import</span> <span class="n">poutine</span>
<span class="kn">from</span> <span class="nn">pyro.infer.autoguide</span> <span class="kn">import</span> <span class="n">AutoDelta</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">JitTraceEnum_ELBO</span><span class="p">,</span> <span class="n">TraceEnum_ELBO</span><span class="p">,</span> <span class="n">TraceTMC_ELBO</span>
<span class="kn">from</span> <span class="nn">pyro.ops.indexing</span> <span class="kn">import</span> <span class="n">Vindex</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">pyro.util</span> <span class="kn">import</span> <span class="n">ignore_jit_warnings</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(relativeCreated) 9d</span><span class="s1"> </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>

<span class="c1"># Add another handler for logging debugging events (e.g. for profiling)</span>
<span class="c1"># in a separate stream that can be captured.</span>
<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>
<span class="n">debug_handler</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
<span class="n">debug_handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">debug_handler</span><span class="o">.</span><span class="n">addFilter</span><span class="p">(</span><span class="nb">filter</span><span class="o">=</span><span class="k">lambda</span> <span class="n">record</span><span class="p">:</span> <span class="n">record</span><span class="o">.</span><span class="n">levelno</span> <span class="o">&lt;=</span> <span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">log</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">debug_handler</span><span class="p">)</span>


<span class="c1"># Let&#39;s start with a simple Hidden Markov Model.</span>
<span class="c1">#</span>
<span class="c1">#     x[t-1] --&gt; x[t] --&gt; x[t+1]</span>
<span class="c1">#        |        |         |</span>
<span class="c1">#        V        V         V</span>
<span class="c1">#     y[t-1]     y[t]     y[t+1]</span>
<span class="c1">#</span>
<span class="c1"># This model includes a plate for the data_dim = 88 keys on the piano. This</span>
<span class="c1"># model has two &quot;style&quot; parameters probs_x and probs_y that we&#39;ll draw from a</span>
<span class="c1"># prior. The latent state is x, and the observed state is y. We&#39;ll drive</span>
<span class="c1"># probs_* with the guide, enumerate over x, and condition on y.</span>
<span class="c1">#</span>
<span class="c1"># Importantly, the dependency structure of the enumerated variables has</span>
<span class="c1"># narrow treewidth, therefore admitting efficient inference by message passing.</span>
<span class="c1"># Pyro&#39;s TraceEnum_ELBO will find an efficient message passing scheme if one</span>
<span class="c1"># exists.</span>
<span class="k">def</span> <span class="nf">model_0</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span>
    <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="c1"># Our prior on transition probabilities will be:</span>
        <span class="c1"># stay in the same state with 90% probability; uniformly jump to another</span>
        <span class="c1"># state with 10% probability.</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># We put a weak prior on the conditional probability of a tone sounding.</span>
        <span class="c1"># We know that on average about 4 of 88 tones are active, so we&#39;ll set a</span>
        <span class="c1"># rough weak prior of 10% of the notes being active at any one time.</span>
        <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="c1"># In this first model we&#39;ll sequentially iterate over sequences in a</span>
    <span class="c1"># minibatch; this will make it easy to reason about tensor shapes.</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">length</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="n">length</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">)):</span>
            <span class="c1"># On the next line, we&#39;ll overwrite the value of x with an updated</span>
            <span class="c1"># value. If we wanted to record all x values, we could instead</span>
            <span class="c1"># write x[t] = pyro.sample(...x[t-1]...).</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span>
                            <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
            <span class="k">with</span> <span class="n">tones_plate</span><span class="p">:</span>
                <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]),</span>
                            <span class="n">obs</span><span class="o">=</span><span class="n">sequence</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
<span class="c1"># To see how enumeration changes the shapes of these sample sites, we can use</span>
<span class="c1"># the Trace.format_shapes() to print shapes at each site:</span>
<span class="c1"># $ python examples/hmm.py -m 0 -n 1 -b 1 -t 5 --print-shapes</span>
<span class="c1"># ...</span>
<span class="c1">#  Sample Sites:</span>
<span class="c1">#   probs_x dist          | 16 16</span>
<span class="c1">#          value          | 16 16</span>
<span class="c1">#   probs_y dist          | 16 88</span>
<span class="c1">#          value          | 16 88</span>
<span class="c1">#     tones dist          |</span>
<span class="c1">#          value       88 |</span>
<span class="c1"># sequences dist          |</span>
<span class="c1">#          value        1 |</span>
<span class="c1">#   x_178_0 dist          |</span>
<span class="c1">#          value    16  1 |</span>
<span class="c1">#   y_178_0 dist    16 88 |</span>
<span class="c1">#          value       88 |</span>
<span class="c1">#   x_178_1 dist    16  1 |</span>
<span class="c1">#          value 16  1  1 |</span>
<span class="c1">#   y_178_1 dist 16  1 88 |</span>
<span class="c1">#          value       88 |</span>
<span class="c1">#   x_178_2 dist 16  1  1 |</span>
<span class="c1">#          value    16  1 |</span>
<span class="c1">#   y_178_2 dist    16 88 |</span>
<span class="c1">#          value       88 |</span>
<span class="c1">#   x_178_3 dist    16  1 |</span>
<span class="c1">#          value 16  1  1 |</span>
<span class="c1">#   y_178_3 dist 16  1 88 |</span>
<span class="c1">#          value       88 |</span>
<span class="c1">#   x_178_4 dist 16  1  1 |</span>
<span class="c1">#          value    16  1 |</span>
<span class="c1">#   y_178_4 dist    16 88 |</span>
<span class="c1">#          value       88 |</span>
<span class="c1">#</span>
<span class="c1"># Notice that enumeration (over 16 states) alternates between two dimensions:</span>
<span class="c1"># -2 and -3.  If we had not used pyro.markov above, each enumerated variable</span>
<span class="c1"># would need its own enumeration dimension.</span>


<span class="c1"># Next let&#39;s make our simple model faster in two ways: first we&#39;ll support</span>
<span class="c1"># vectorized minibatches of data, and second we&#39;ll support the PyTorch jit</span>
<span class="c1"># compiler.  To add batch support, we&#39;ll introduce a second plate &quot;sequences&quot;</span>
<span class="c1"># and randomly subsample data to size batch_size.  To add jit support we</span>
<span class="c1"># silence some warnings and try to avoid dynamic program structure.</span>

<span class="c1"># Note that this is the &quot;HMM&quot; model in reference [1] (with the difference that</span>
<span class="c1"># in [1] the probabilities probs_x and probs_y are not MAP-regularized with</span>
<span class="c1"># Dirichlet and Beta distributions for any of the models)</span>
<span class="k">def</span> <span class="nf">model_1</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1"># Sometimes it is safe to ignore jit warnings. Here we use the</span>
    <span class="c1"># pyro.util.ignore_jit_warnings context manager to silence warnings about</span>
    <span class="c1"># conversion to integer, since we know all three numbers will be the same</span>
    <span class="c1"># across all invocations to the model.</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>
    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># We subsample batch_size items out of num_sequences items. Note that since</span>
    <span class="c1"># we&#39;re using dim=-1 for the notes plate, we need to batch over a different</span>
    <span class="c1"># dimension, here dim=-2.</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># If we are not using the jit, then we can vary the program structure</span>
        <span class="c1"># each call by running for a dynamically determined number of time</span>
        <span class="c1"># steps, lengths.max(). However if we are using the jit, then we try to</span>
        <span class="c1"># keep a single program structure for all minibatches; the fixed</span>
        <span class="c1"># structure ends up being faster since each program structure would</span>
        <span class="c1"># need to trigger a new jit compile stage.</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_length</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">())):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="k">with</span> <span class="n">tones_plate</span><span class="p">:</span>
                    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]),</span>
                                <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>
<span class="c1"># Let&#39;s see how batching changes the shapes of sample sites:</span>
<span class="c1"># $ python examples/hmm.py -m 1 -n 1 -t 5 --batch-size=10 --print-shapes</span>
<span class="c1"># ...</span>
<span class="c1">#  Sample Sites:</span>
<span class="c1">#   probs_x dist             | 16 16</span>
<span class="c1">#          value             | 16 16</span>
<span class="c1">#   probs_y dist             | 16 88</span>
<span class="c1">#          value             | 16 88</span>
<span class="c1">#     tones dist             |</span>
<span class="c1">#          value          88 |</span>
<span class="c1"># sequences dist             |</span>
<span class="c1">#          value          10 |</span>
<span class="c1">#       x_0 dist       10  1 |</span>
<span class="c1">#          value    16  1  1 |</span>
<span class="c1">#       y_0 dist    16 10 88 |</span>
<span class="c1">#          value       10 88 |</span>
<span class="c1">#       x_1 dist    16 10  1 |</span>
<span class="c1">#          value 16  1  1  1 |</span>
<span class="c1">#       y_1 dist 16  1 10 88 |</span>
<span class="c1">#          value       10 88 |</span>
<span class="c1">#       x_2 dist 16  1 10  1 |</span>
<span class="c1">#          value    16  1  1 |</span>
<span class="c1">#       y_2 dist    16 10 88 |</span>
<span class="c1">#          value       10 88 |</span>
<span class="c1">#       x_3 dist    16 10  1 |</span>
<span class="c1">#          value 16  1  1  1 |</span>
<span class="c1">#       y_3 dist 16  1 10 88 |</span>
<span class="c1">#          value       10 88 |</span>
<span class="c1">#       x_4 dist 16  1 10  1 |</span>
<span class="c1">#          value    16  1  1 |</span>
<span class="c1">#       y_4 dist    16 10 88 |</span>
<span class="c1">#          value       10 88 |</span>
<span class="c1">#</span>
<span class="c1"># Notice that we&#39;re now using dim=-2 as a batch dimension (of size 10),</span>
<span class="c1"># and that the enumeration dimensions are now dims -3 and -4.</span>


<span class="c1"># Next let&#39;s add a dependency of y[t] on y[t-1].</span>
<span class="c1">#</span>
<span class="c1">#     x[t-1] --&gt; x[t] --&gt; x[t+1]</span>
<span class="c1">#        |        |         |</span>
<span class="c1">#        V        V         V</span>
<span class="c1">#     y[t-1] --&gt; y[t] --&gt; y[t+1]</span>
<span class="c1">#</span>
<span class="c1"># Note that this is the &quot;arHMM&quot; model in reference [1].</span>
<span class="k">def</span> <span class="nf">model_2</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>
    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_length</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">())):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="c1"># Note the broadcasting tricks here: to index probs_y on tensors x and y,</span>
                <span class="c1"># we also need a final tensor for the tones dimension. This is conveniently</span>
                <span class="c1"># provided by the plate associated with that dimension.</span>
                <span class="k">with</span> <span class="n">tones_plate</span> <span class="k">as</span> <span class="n">tones</span><span class="p">:</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tones</span><span class="p">]),</span>
                                    <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>


<span class="c1"># Next consider a Factorial HMM with two hidden states.</span>
<span class="c1">#</span>
<span class="c1">#    w[t-1] ----&gt; w[t] ---&gt; w[t+1]</span>
<span class="c1">#        \ x[t-1] --\-&gt; x[t] --\-&gt; x[t+1]</span>
<span class="c1">#         \  /       \  /       \  /</span>
<span class="c1">#          \/         \/         \/</span>
<span class="c1">#        y[t-1]      y[t]      y[t+1]</span>
<span class="c1">#</span>
<span class="c1"># Note that since the joint distribution of each y[t] depends on two variables,</span>
<span class="c1"># those two variables become dependent. Therefore during enumeration, the</span>
<span class="c1"># entire joint space of these variables w[t],x[t] needs to be enumerated.</span>
<span class="c1"># For that reason, we set the dimension of each to the square root of the</span>
<span class="c1"># target hidden dimension.</span>
<span class="c1">#</span>
<span class="c1"># Note that this is the &quot;FHMM&quot; model in reference [1].</span>
<span class="k">def</span> <span class="nf">model_3</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>
    <span class="n">hidden_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># split between w and x</span>
    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_w</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_w&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_length</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">())):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;w_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_w</span><span class="p">[</span><span class="n">w</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="k">with</span> <span class="n">tones_plate</span> <span class="k">as</span> <span class="n">tones</span><span class="p">:</span>
                    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tones</span><span class="p">]),</span>
                                <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>


<span class="c1"># By adding a dependency of x on w, we generalize to a</span>
<span class="c1"># Dynamic Bayesian Network.</span>
<span class="c1">#</span>
<span class="c1">#     w[t-1] ----&gt; w[t] ---&gt; w[t+1]</span>
<span class="c1">#        |  \       |  \       |   \</span>
<span class="c1">#        | x[t-1] ----&gt; x[t] ----&gt; x[t+1]</span>
<span class="c1">#        |   /      |   /      |   /</span>
<span class="c1">#        V  /       V  /       V  /</span>
<span class="c1">#     y[t-1]       y[t]      y[t+1]</span>
<span class="c1">#</span>
<span class="c1"># Note that message passing here has roughly the same cost as with the</span>
<span class="c1"># Factorial HMM, but this model has more parameters.</span>
<span class="c1">#</span>
<span class="c1"># Note that this is the &quot;PFHMM&quot; model in reference [1].</span>
<span class="k">def</span> <span class="nf">model_4</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>
    <span class="n">hidden_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># split between w and x</span>
    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_w</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_w&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand_by</span><span class="p">([</span><span class="n">hidden_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">])</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="c1"># Note the broadcasting tricks here: we declare a hidden torch.arange and</span>
        <span class="c1"># ensure that w and x are always tensors so we can unsqueeze them below,</span>
        <span class="c1"># thus ensuring that the x sample sites have correct distribution shape.</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_length</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">())):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">w</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;w_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_w</span><span class="p">[</span><span class="n">w</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span>
                                <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">Vindex</span><span class="p">(</span><span class="n">probs_x</span><span class="p">)[</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="k">with</span> <span class="n">tones_plate</span> <span class="k">as</span> <span class="n">tones</span><span class="p">:</span>
                    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">tones</span><span class="p">]),</span>
                                <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>


<span class="c1"># Next let&#39;s consider a neural HMM model.</span>
<span class="c1">#</span>
<span class="c1">#     x[t-1] --&gt; x[t] --&gt; x[t+1]   } standard HMM +</span>
<span class="c1">#        |        |         |</span>
<span class="c1">#        V        V         V</span>
<span class="c1">#     y[t-1] --&gt; y[t] --&gt; y[t+1]   } neural likelihood</span>
<span class="c1">#</span>
<span class="c1"># First let&#39;s define a neural net to generate y logits.</span>
<span class="k">class</span> <span class="nc">TonesGenerator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_dim</span> <span class="o">=</span> <span class="n">data_dim</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_to_hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">nn_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_to_hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">nn_channels</span> <span class="o">*</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">nn_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">nn_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_logits</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">nn_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># Hidden units depend on two inputs: a one-hot encoded categorical variable x, and</span>
        <span class="c1"># a bernoulli variable y. Whereas x will typically be enumerated, y will be observed.</span>
        <span class="c1"># We apply x_to_hidden independently from y_to_hidden, then broadcast the non-enumerated</span>
        <span class="c1"># y part up to the enumerated x part in the + operation.</span>
        <span class="n">x_onehot</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,))</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_dim</span><span class="p">)))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_to_hidden</span><span class="p">(</span><span class="n">x_onehot</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_to_hidden</span><span class="p">(</span><span class="n">y_conv</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_logits</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>


<span class="c1"># We will create a single global instance later.</span>
<span class="n">tones_generator</span> <span class="o">=</span> <span class="bp">None</span>


<span class="c1"># The neural HMM model now uses tones_generator at each time step.</span>
<span class="c1">#</span>
<span class="c1"># Note that this is the &quot;nnHMM&quot; model in reference [1].</span>
<span class="k">def</span> <span class="nf">model_5</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>

    <span class="c1"># Initialize a global module instance if needed.</span>
    <span class="k">global</span> <span class="n">tones_generator</span>
    <span class="k">if</span> <span class="n">tones_generator</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">tones_generator</span> <span class="o">=</span> <span class="n">TonesGenerator</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">)</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;tones_generator&quot;</span><span class="p">,</span> <span class="n">tones_generator</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">data_dim</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_length</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">())):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x</span><span class="p">[</span><span class="n">x</span><span class="p">]),</span>
                                <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="c1"># Note that since each tone depends on all tones at a previous time step</span>
                <span class="c1"># the tones at different time steps now need to live in separate plates.</span>
                <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span>
                                    <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">tones_generator</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)),</span>
                                    <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>


<span class="c1"># Next let&#39;s consider a second-order HMM model</span>
<span class="c1"># in which x[t+1] depends on both x[t] and x[t-1].</span>
<span class="c1">#</span>
<span class="c1">#                     _______&gt;______</span>
<span class="c1">#         _____&gt;_____/______        \</span>
<span class="c1">#        /          /       \        \</span>
<span class="c1">#     x[t-1] --&gt; x[t] --&gt; x[t+1] --&gt; x[t+2]</span>
<span class="c1">#        |        |          |          |</span>
<span class="c1">#        V        V          V          V</span>
<span class="c1">#     y[t-1]     y[t]     y[t+1]     y[t+2]</span>
<span class="c1">#</span>
<span class="c1">#  Note that in this model (in contrast to the previous model) we treat</span>
<span class="c1">#  the transition and emission probabilities as parameters (so they have no prior).</span>
<span class="c1">#</span>
<span class="c1"># Note that this is the &quot;2HMM&quot; model in reference [1].</span>
<span class="k">def</span> <span class="nf">model_6</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
    <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>
    <span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">args</span><span class="o">.</span><span class="n">raftery_parameterization</span><span class="p">:</span>
        <span class="c1"># Explicitly parameterize the full tensor of transition probabilities, which</span>
        <span class="c1"># has hidden_dim cubed entries.</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                             <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">simplex</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Use the more parsimonious &quot;Raftery&quot; parameterization of</span>
        <span class="c1"># the tensor of transition probabilities. See reference:</span>
        <span class="c1"># Raftery, A. E. A model for high-order markov chains.</span>
        <span class="c1"># Journal of the Royal Statistical Society. 1985.</span>
        <span class="n">probs_x1</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;probs_x1&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                              <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">simplex</span><span class="p">)</span>
        <span class="n">probs_x2</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;probs_x2&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
                              <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">simplex</span><span class="p">)</span>
        <span class="n">mix_lambda</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;mix_lambda&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">unit_interval</span><span class="p">)</span>
        <span class="c1"># we use broadcasting to combine two tensors of shape (hidden_dim, hidden_dim) and</span>
        <span class="c1"># (hidden_dim, 1, hidden_dim) to obtain a tensor of shape (hidden_dim, hidden_dim, hidden_dim)</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">mix_lambda</span> <span class="o">*</span> <span class="n">probs_x1</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">mix_lambda</span><span class="p">)</span> <span class="o">*</span> <span class="n">probs_x2</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">probs_y</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s2">&quot;probs_y&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">),</span>
                         <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">unit_interval</span><span class="p">)</span>
    <span class="n">tones_plate</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;tones&quot;</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">x_curr</span><span class="p">,</span> <span class="n">x_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># we need to pass the argument `history=2&#39; to `pyro.markov()`</span>
        <span class="c1"># since our model is now 2-markov</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">markov</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="n">history</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
                <span class="n">probs_x_t</span> <span class="o">=</span> <span class="n">Vindex</span><span class="p">(</span><span class="n">probs_x</span><span class="p">)[</span><span class="n">x_prev</span><span class="p">,</span> <span class="n">x_curr</span><span class="p">]</span>
                <span class="n">x_prev</span><span class="p">,</span> <span class="n">x_curr</span> <span class="o">=</span> <span class="n">x_curr</span><span class="p">,</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;x_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">probs_x_t</span><span class="p">),</span>
                                                     <span class="n">infer</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;enumerate&quot;</span><span class="p">:</span> <span class="s2">&quot;parallel&quot;</span><span class="p">})</span>
                <span class="k">with</span> <span class="n">tones_plate</span><span class="p">:</span>
                    <span class="n">probs_y_t</span> <span class="o">=</span> <span class="n">probs_y</span><span class="p">[</span><span class="n">x_curr</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
                    <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs_y_t</span><span class="p">),</span>
                                <span class="n">obs</span><span class="o">=</span><span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>


<span class="c1"># Next we demonstrate how to parallelize the neural HMM above using Pyro&#39;s</span>
<span class="c1"># DiscreteHMM distribution. This model is equivalent to model_5 above, but we</span>
<span class="c1"># manually unroll loops and fuse ops, leading to a single sample statement.</span>
<span class="c1"># DiscreteHMM can lead to over 10x speedup in models where it is applicable.</span>
<span class="k">def</span> <span class="nf">model_7</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
        <span class="n">num_sequences</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">data_dim</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">sequences</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_sequences</span><span class="p">,)</span>
        <span class="k">assert</span> <span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">max_length</span>

    <span class="c1"># Initialize a global module instance if needed.</span>
    <span class="k">global</span> <span class="n">tones_generator</span>
    <span class="k">if</span> <span class="n">tones_generator</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">tones_generator</span> <span class="o">=</span> <span class="n">TonesGenerator</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">data_dim</span><span class="p">)</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;tones_generator&quot;</span><span class="p">,</span> <span class="n">tones_generator</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">poutine</span><span class="o">.</span><span class="n">mask</span><span class="p">(</span><span class="n">mask</span><span class="o">=</span><span class="n">include_prior</span><span class="p">):</span>
        <span class="n">probs_x</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;probs_x&quot;</span><span class="p">,</span>
                              <span class="n">dist</span><span class="o">.</span><span class="n">Dirichlet</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span>
                                  <span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;sequences&quot;</span><span class="p">,</span> <span class="n">num_sequences</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="k">as</span> <span class="n">batch</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">]</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">sequences</span><span class="p">[</span><span class="n">batch</span><span class="p">,</span> <span class="p">:</span><span class="n">lengths</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">init_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,),</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
        <span class="n">init_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">trans_logits</span> <span class="o">=</span> <span class="n">probs_x</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">ignore_jit_warnings</span><span class="p">():</span>
            <span class="n">obs_dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">tones_generator</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)))</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">obs_dist</span> <span class="o">=</span> <span class="n">obs_dist</span><span class="o">.</span><span class="n">mask</span><span class="p">((</span><span class="n">t</span> <span class="o">&lt;</span> <span class="n">lengths</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">hmm_dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">DiscreteHMM</span><span class="p">(</span><span class="n">init_logits</span><span class="p">,</span> <span class="n">trans_logits</span><span class="p">,</span> <span class="n">obs_dist</span><span class="p">)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">hmm_dist</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>


<span class="n">models</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s1">&#39;model_&#39;</span><span class="p">):]:</span> <span class="n">model</span>
          <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
          <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;model_&#39;</span><span class="p">)}</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">(</span><span class="s1">&#39;torch.cuda.FloatTensor&#39;</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Loading data&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">poly</span><span class="o">.</span><span class="n">JSB_CHORALES</span><span class="p">)</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training {} on {} sequences&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;sequences&#39;</span><span class="p">])))</span>
    <span class="n">sequences</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;sequences&#39;</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;sequence_lengths&#39;</span><span class="p">]</span>

    <span class="c1"># find all the notes that are present at least once in the training set</span>
    <span class="n">present_notes</span> <span class="o">=</span> <span class="p">((</span><span class="n">sequences</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># remove notes that are never played (we remove 37/88 notes)</span>
    <span class="n">sequences</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">present_notes</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">truncate</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">truncate</span><span class="p">)</span>
        <span class="n">sequences</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="p">:</span><span class="n">args</span><span class="o">.</span><span class="n">truncate</span><span class="p">]</span>
    <span class="n">num_observations</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="n">__debug__</span><span class="p">)</span>

    <span class="c1"># We&#39;ll train using MAP Baum-Welch, i.e. MAP estimation while marginalizing</span>
    <span class="c1"># out the hidden state x. This is accomplished via an automatic guide that</span>
    <span class="c1"># learns point estimates of all of our conditional probability tables,</span>
    <span class="c1"># named probs_*.</span>
    <span class="n">guide</span> <span class="o">=</span> <span class="n">AutoDelta</span><span class="p">(</span><span class="n">poutine</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">expose_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">msg</span><span class="p">:</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;probs_&quot;</span><span class="p">)))</span>

    <span class="c1"># To help debug our tensor shapes, let&#39;s print the shape of each site&#39;s</span>
    <span class="c1"># distribution, value, and log_prob tensor. Note this information is</span>
    <span class="c1"># automatically printed on most errors inside SVI.</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">print_shapes</span><span class="p">:</span>
        <span class="n">first_available_dim</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="n">model_0</span> <span class="k">else</span> <span class="o">-</span><span class="mi">3</span>
        <span class="n">guide_trace</span> <span class="o">=</span> <span class="n">poutine</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">guide</span><span class="p">)</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span>
            <span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">model_trace</span> <span class="o">=</span> <span class="n">poutine</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
            <span class="n">poutine</span><span class="o">.</span><span class="n">replay</span><span class="p">(</span><span class="n">poutine</span><span class="o">.</span><span class="n">enum</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">first_available_dim</span><span class="p">),</span> <span class="n">guide_trace</span><span class="p">))</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span>
            <span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">model_trace</span><span class="o">.</span><span class="n">format_shapes</span><span class="p">())</span>

    <span class="c1"># Enumeration requires a TraceEnum elbo and declaring the max_plate_nesting.</span>
    <span class="c1"># All of our models have two plates: &quot;data&quot; and &quot;tones&quot;.</span>
    <span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">({</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">})</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">tmc</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;jit support not yet added for TraceTMC_ELBO&quot;</span><span class="p">)</span>
        <span class="n">elbo</span> <span class="o">=</span> <span class="n">TraceTMC_ELBO</span><span class="p">(</span><span class="n">max_plate_nesting</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="n">model_0</span> <span class="k">else</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">tmc_model</span> <span class="o">=</span> <span class="n">poutine</span><span class="o">.</span><span class="n">infer_config</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="k">lambda</span> <span class="n">msg</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;num_samples&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">tmc_num_samples</span><span class="p">,</span> <span class="s2">&quot;expand&quot;</span><span class="p">:</span> <span class="bp">False</span><span class="p">}</span> <span class="k">if</span> <span class="n">msg</span><span class="p">[</span><span class="s2">&quot;infer&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;enumerate&quot;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;parallel&quot;</span> <span class="k">else</span> <span class="p">{})</span>  <span class="c1"># noqa: E501</span>
        <span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">tmc_model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">elbo</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Elbo</span> <span class="o">=</span> <span class="n">JitTraceEnum_ELBO</span> <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="k">else</span> <span class="n">TraceEnum_ELBO</span>
        <span class="n">elbo</span> <span class="o">=</span> <span class="n">Elbo</span><span class="p">(</span><span class="n">max_plate_nesting</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="n">model_0</span> <span class="k">else</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">strict_enumeration_warning</span><span class="o">=</span><span class="p">(</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">model_7</span><span class="p">),</span>
                    <span class="n">jit_options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;time_compilation&quot;</span><span class="p">:</span> <span class="n">args</span><span class="o">.</span><span class="n">time_compilation</span><span class="p">})</span>
        <span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">optim</span><span class="p">,</span> <span class="n">elbo</span><span class="p">)</span>

    <span class="c1"># We&#39;ll train on small minibatches.</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Step</span><span class="se">\t</span><span class="s1">Loss&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;{: &gt;5d}</span><span class="se">\t</span><span class="s1">{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">num_observations</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">jit</span> <span class="ow">and</span> <span class="n">args</span><span class="o">.</span><span class="n">time_compilation</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;time to compile: {} s.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">elbo</span><span class="o">.</span><span class="n">_differentiable_loss</span><span class="o">.</span><span class="n">compile_time</span><span class="p">))</span>

    <span class="c1"># We evaluate on the entire training dataset,</span>
    <span class="c1"># excluding the prior term so our results are comparable across models.</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">elbo</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;training loss = {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_loss</span> <span class="o">/</span> <span class="n">num_observations</span><span class="p">))</span>

    <span class="c1"># Finally we evaluate on the test dataset.</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Evaluating on {} test sequences&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;sequences&#39;</span><span class="p">])))</span>
    <span class="n">sequences</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;sequences&#39;</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="n">present_notes</span><span class="p">]</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;sequence_lengths&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">truncate</span><span class="p">:</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">truncate</span><span class="p">)</span>
    <span class="n">num_observations</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lengths</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>

    <span class="c1"># note that since we removed unseen notes above (to make the problem a bit easier and for</span>
    <span class="c1"># numerical stability) this test loss may not be directly comparable to numbers</span>
    <span class="c1"># reported on this dataset elsewhere.</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">elbo</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">sequences</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">include_prior</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;test loss = {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span> <span class="o">/</span> <span class="n">num_observations</span><span class="p">))</span>

    <span class="c1"># We expect models with higher capacity to perform better,</span>
    <span class="c1"># but eventually overfit to the training set.</span>
    <span class="n">capacity</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                   <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">get_param_store</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;{} capacity = {} parameters&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">capacity</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">pyro</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;1.3.0&#39;</span><span class="p">)</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;MAP Baum-Welch learning Bach Chorales&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-m&quot;</span><span class="p">,</span> <span class="s2">&quot;--model&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;one of: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">()))))</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-n&quot;</span><span class="p">,</span> <span class="s2">&quot;--num-steps&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-b&quot;</span><span class="p">,</span> <span class="s2">&quot;--batch-size&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-d&quot;</span><span class="p">,</span> <span class="s2">&quot;--hidden-dim&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-nn&quot;</span><span class="p">,</span> <span class="s2">&quot;--nn-dim&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-nc&quot;</span><span class="p">,</span> <span class="s2">&quot;--nn-channels&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-lr&quot;</span><span class="p">,</span> <span class="s2">&quot;--learning-rate&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-t&quot;</span><span class="p">,</span> <span class="s2">&quot;--truncate&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-p&quot;</span><span class="p">,</span> <span class="s2">&quot;--print-shapes&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--seed&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--cuda&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--jit&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--time-compilation&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;-rp&#39;</span><span class="p">,</span> <span class="s1">&#39;--raftery-parameterization&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--tmc&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span><span class="p">,</span>
                        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use Tensor Monte Carlo instead of exact enumeration &quot;</span>
                             <span class="s2">&quot;to estimate the marginal likelihood. You probably don&#39;t want to do this, &quot;</span>
                             <span class="s2">&quot;except to see that TMC makes Monte Carlo gradient estimation feasible &quot;</span>
                             <span class="s2">&quot;even with very large numbers of non-reparametrized variables.&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--tmc-num-samples&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
    <span class="n">main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lda.html" class="btn btn-neutral float-right" title="Latent Dirichlet Allocation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="cevae.html" class="btn btn-neutral float-left" title="Causal Effect VAE" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Uber Technologies, Inc; 编译 by Heyang Gong

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>