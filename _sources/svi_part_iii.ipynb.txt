{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI Part III: ELBO 梯度估计\n",
    "\n",
    "本文讲解 SVI 的 ELBO 优化理论，如何得到 ELBO Gradient Estimators。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾：\n",
    "\n",
    "- 因为 `model = primitive r.v. + deterministic function`, 那么 `guide` 就应该对应的是此公式中 `latent r.v.` 给定部分 `observed r.v.` 的后验分布。\n",
    "- 在变分自编码器中，用来近似后验分布的 `guide` $q_\\phi(z)$ 是局部的，意味着对一个每个样本 $x_i$, `latent r.v.` 的后验分布 $q_\\phi(z|x_i)$ 都不相同，我们需要学习与样本个数相同数量的后验分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "我们定义一个 Pyro model $p_{\\theta}({\\bf x}, {\\bf z}) = p_{\\theta}({\\bf x}|{\\bf z}) p_{\\theta}({\\bf z})$, where ${\\bf x}$ 为可观测变量 and ${\\bf z}$ 为潜变量。我们还定义一个 Pyro guide $q_{\\phi}({\\bf z})$（也就是变分分布）。 这里 ${\\theta}$ and $\\phi$ 分别被成为 model and guide 变分参数. (In particular these are _not_ random variables that call for a Bayesian treatment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(通过优化 ELBO 来最大化$\\log p_{\\theta}({\\bf x})$) We'd like to maximize the log evidence $\\log p_{\\theta}({\\bf x})$ by maximizing the ELBO (the evidence lower bound) given by \n",
    "\n",
    "$${\\rm ELBO} \\equiv \\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
    "\\log p_{\\theta}({\\bf x}, {\\bf z}) - \\log q_{\\phi}({\\bf z})\n",
    "\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(使用梯度下降法优化 ELBO) To do this we're going to take (stochastic) gradient steps on the ELBO in the parameter space $\\{ \\theta, \\phi \\}$ (有关此方法的早期工作，请参见参考文献[1,2]). So we need to be able to compute unbiased estimates of \n",
    "\n",
    "$$\\nabla_{\\theta,\\phi} {\\rm ELBO} = \\nabla_{\\theta,\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
    "\\log p_{\\theta}({\\bf x}, {\\bf z}) - \\log q_{\\phi}({\\bf z})\n",
    "\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一般的随机函数 `model()` and `guide()` 如何计算估计上面梯度呢? To simplify notation let's generalize our discussion a bit and ask how we can compute gradients of expectations of an arbitrary cost function $f({\\bf z})$. Let's also drop any distinction between $\\theta$ and $\\phi$. 问题转化成为了计算：\n",
    "\n",
    "$$\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]$$\n",
    "\n",
    "让我们从最简单的情况开始。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单情况: 可重参数化\n",
    "\n",
    "Suppose that we can reparameterize things such that \n",
    "\n",
    "$$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [f_{\\phi}({\\bf z}) \\right]\n",
    "=\\mathbb{E}_{q({\\bf \\epsilon})} \\left [f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]$$\n",
    "\n",
    "Crucially we've moved all the $\\phi$ dependence inside of the expectation; $q({\\bf \\epsilon})$ is a fixed distribution with no dependence on $\\phi$. 这种重新参数化可以适用许多分布（例如正态分布）；更多详情参见参考文献[3]. This kind of reparameterization can be done for many distributions (e.g. the normal distribution); see reference [3] for a discussion. In this case we can pass the gradient straight through the expectation to get\n",
    "\n",
    "$$\\nabla_{\\phi}\\mathbb{E}_{q({\\bf \\epsilon})} \\left [f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]=\n",
    "\\mathbb{E}_{q({\\bf \\epsilon})} \\left [\\nabla_{\\phi}f_{\\phi}(g_{\\phi}({\\bf \\epsilon})) \\right]$$\n",
    "\n",
    "Assuming $f(\\cdot)$ and $g(\\cdot)$ are sufficiently smooth, we can now get unbiased estimates of the gradient of interest by taking a Monte Carlo estimate of this expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tricky case: 不可重参数化\n",
    "\n",
    "\n",
    "如果我们不能进行上述重新参数化怎么办？不幸的是，许多感兴趣的分布（例如所有离散分布）都是这种情况。在这种情况下，我们的估算器 takes a bit more complicated form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by expanding the gradient of interest as\n",
    "\n",
    "$$\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]= \n",
    "\\nabla_{\\phi} \\int d{\\bf z} \\; q_{\\phi}({\\bf z}) f_{\\phi}({\\bf z})$$\n",
    "\n",
    "使用链式法则得到：\n",
    "\n",
    "$$ \\int d{\\bf z} \\; \\left \\{ (\\nabla_{\\phi}  q_{\\phi}({\\bf z})) f_{\\phi}({\\bf z}) + q_{\\phi}({\\bf z})(\\nabla_{\\phi} f_{\\phi}({\\bf z}))\\right \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we run into a problem. We know how to generate samples from $q(\\cdot)$&mdash;we just run the guide forward&mdash;but $\\nabla_{\\phi}  q_{\\phi}({\\bf z})$ isn't even a valid probability density. 因此，我们需要对这个公式进行 massage (也就是简单变形)，使其以期望 w.r.t. $q(\\cdot)$ 的形式出现. This is easily done using the identity\n",
    "\n",
    "$$ \\nabla_{\\phi}  q_{\\phi}({\\bf z}) = \n",
    "q_{\\phi}({\\bf z})\\nabla_{\\phi} \\log q_{\\phi}({\\bf z})$$\n",
    "\n",
    "which allows us to rewrite the gradient of interest as \n",
    "\n",
    "$$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "(\\nabla_{\\phi} \\log q_{\\phi}({\\bf z})) f_{\\phi}({\\bf z}) + \\nabla_{\\phi} f_{\\phi}({\\bf z})\\right]$$\n",
    "\n",
    "This form of the gradient&mdash;variously known as the REINFORCE estimator or the score function estimator or the likelihood ratio estimator&mdash;适用于简单的蒙特卡洛估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one way to package this result (which is convenient for implementation) is to introduce a surrogate objective function\n",
    "\n",
    "$${\\rm surrogate \\;objective} \\equiv\n",
    "\\log q_{\\phi}({\\bf z}) \\overline{f_{\\phi}({\\bf z})} + f_{\\phi}({\\bf z})$$  \n",
    "\n",
    "Here the bar indicates that the term is held constant (i.e. it is not to be differentiated w.r.t. $\\phi$). 为了获得（单样本）蒙特卡洛梯度估计，我们对潜变量进行了采样 w.r.t. guide，计算替代目标函数，并进行微分。The result is an unbiased estimate of $\\nabla_{\\phi}\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\n",
    "f_{\\phi}({\\bf z}) \\right]$. In equations:\n",
    "\n",
    "$$\\nabla_{\\phi} {\\rm ELBO} = \\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [ \n",
    "\\nabla_{\\phi} ({\\rm surrogate \\; objective}) \\right]$$\n",
    "\n",
    "\n",
    "有两个策略可以继续改进, 一个策略是考虑使用特殊结构的损失函数, 另外一个策略是改进梯度方向(像动量法一样)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缓解方差问题策略\n",
    "\n",
    "<small> *Variance 问题：为什么希望做 MLE Deep Learning* </small> \n",
    "\n",
    "我们现在有了一个通用方法 for an unbiased gradient estimator of expectations of cost functions. 不幸的是, in the more general case where our $q(\\cdot)$ includes non-reparameterizable random variables, 该估计量倾向于具有高方差. Indeed in many cases of interest the variance is so high that the estimator is effectively unusable. 所以我们需要减少方差的策略 (for a discussion see reference [4]). We're going to pursue two strategies.\n",
    "\n",
    "- The first strategy takes advantage of the particular structure of the cost function $f(\\cdot)$. \n",
    "- The second strategy effectively introduces a way to reduce variance by using information from previous estimates of \n",
    "$\\mathbb{E}_{q_{\\phi}({\\bf z})} [ f_{\\phi}({\\bf z})]$. As such it is somewhat analogous to using momentum in stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Variance via Dependency Structure\n",
    "\n",
    "利用概率图结构，也就是概率分布结构减少方差，本部分内容首先介绍其相关理论，然后给出一个 Rao-Blackwellization 例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的讨论中 we stuck to a general cost function $f_{\\phi}({\\bf z})$. We could continue in this vein (the approach we're about to discuss is applicable in the general case) but for concreteness let's zoom back in. 在随机变分推断的过程中，我们感兴趣的 cost function 有如下形式：\n",
    "\n",
    "$$\\log p_{\\theta}({\\bf x} | {\\rm Pa}_p ({\\bf x})) +\n",
    "\\sum_i \\log p_{\\theta}({\\bf z}_i | {\\rm Pa}_p ({\\bf z}_i)) \n",
    "- \\sum_i \\log q_{\\phi}({\\bf z}_i | {\\rm Pa}_q ({\\bf z}_i))$$\n",
    "\n",
    "where we've broken the log ratio $\\log p_{\\theta}({\\bf x}, {\\bf z})/q_{\\phi}({\\bf z})$ into an observation log likelihood piece and a sum over the different latent random variables $\\{{\\bf z}_i \\}$. We've also introduced the notation ${\\rm Pa}_p (\\cdot)$ and ${\\rm Pa}_q (\\cdot)$ to denote the parents of a given random variable in the model and in the guide, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(读者可能会担心 what the appropriate notion of dependency would be in the case of general stochastic functions; 这里我们仅仅指 regular ol' dependency within a single execution trace). The point is that different terms in the cost function have different dependencies on the random variables $\\{ {\\bf z}_i \\}$ and this is something we can leverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简而言之, 对于任何不可重参数化的潜变量 ${\\bf z}_i$ the surrogate objective is going to have a term \n",
    "\n",
    "$$\\log q_{\\phi}({\\bf z}_i) \\overline{f_{\\phi}({\\bf z})} $$\n",
    "\n",
    "It turns out that we can remove some of the terms in $\\overline{f_{\\phi}({\\bf z})}$ and still get an unbiased gradient estimator; furthermore, doing so will generally decrease the variance. 具体来说 (see reference [4] for details) we can remove any terms in $\\overline{f_{\\phi}({\\bf z})}$ that are not downstream of the latent variable ${\\bf z}_i$ (downstream w.r.t. to the dependency structure of the guide). 请注意，这种一般性的技巧（通常通过分析处理某些随机变量以减少差异）通常被称为 Rao-Blackwellization。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Pyro中，所有这些逻辑都由`SVI`类自动处理。In particular as long as we use a `TraceGraph_ELBO` loss, Pyro will **keep track of the dependency structure** within the execution traces of the model and guide and **construct a surrogate objective that has all the unnecessary terms removed**:\n",
    "\n",
    "```python\n",
    "svi = SVI(model, guide, optimizer, TraceGraph_ELBO())\n",
    "```\n",
    "\n",
    "请注意，利用此随机变量依赖关系信息需要额外的计算，所以 `TraceGraph_ELBO` 仅应在模型具有不可重参数化的随机变量的情况下使用； in most applications `Trace_ELBO` suffices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rao-Blackwellization 例子\n",
    "\n",
    "Suppose we have a gaussian mixture model with $K$ components. For each data point we: (i) first sample the component distribution $k \\in [1,...,K]$; and (ii) observe the data point using the $k^{\\rm th}$ component distribution. The simplest way to write down a model of this sort is as follows:\n",
    "\n",
    "```python\n",
    "ks = pyro.sample(\"k\", dist.Categorical(probs)\n",
    "                          .to_event(1))\n",
    "pyro.sample(\"obs\", dist.Normal(locs[ks], scale)\n",
    "                       .to_event(1),\n",
    "            obs=data)\n",
    "```\n",
    "\n",
    "Since the user hasn't taken care to mark any of the conditional independencies in the model, the gradient estimator constructed by Pyro's `SVI` class is unable to take advantage of Rao-Blackwellization, with the result that the gradient estimator will tend to suffer from high variance. To address this problem the user needs to explicitly mark the conditional independence. Happily, this is not much work:\n",
    "\n",
    "\n",
    "```python\n",
    "# mark conditional independence \n",
    "# (assumed to be along the rightmost tensor dimension)\n",
    "with pyro.plate(\"foo\", data.size(-1)):\n",
    "    ks = pyro.sample(\"k\", dist.Categorical(probs))\n",
    "    pyro.sample(\"obs\", dist.Normal(locs[ks], scale),\n",
    "                obs=data)\n",
    "```      \n",
    "\n",
    "That's all there is to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside: Dependency tracking in Pyro \n",
    "\n",
    "最后，谈谈 dependency tracking. 在包含任意Python代码的随机函数中track dependency 有些棘手。Pyro中当前实现的方法类似于 WebPPL 中使用的方法(cf. reference [5]). Briefly, a conservative notion of dependency is used that relies on sequential ordering. If random variable ${\\bf z}_2$ follows ${\\bf z}_1$ in a given stochastic function then ${\\bf z}_2$ _may be_ dependent on ${\\bf z}_1$ and therefore _is_ assumed to be dependent. To mitigate the overly coarse conclusions that can be drawn by this kind of dependency tracking, Pyro includes constructs for declaring things as independent, namely `plate` and `markov` ([参见上一教程](svi_part_ii.ipynb)). \n",
    "\n",
    "For use cases with non-reparameterizable variables, it is therefore important for the user to make use of these constructs (when applicable) to take full advantage of the variance reduction provided by `SVI`. In some cases it may also pay to consider reordering random variables within a stochastic function (if possible). 还值得注意的是，我们希望在将来的Pyro版本中添加更精细的 dependency tracking notations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Variance with Data-Dependent Baselines\n",
    "\n",
    "减少方差的第二种策略 in our ELBO gradient estimator goes under the name of baselines (see e.g. reference [6], 类似于动量梯度下降法). It actually makes use of the same bit of math that underlies the variance reduction strategy discussed above, except now instead of removing terms we're going to add terms. 基本上，instead of removing terms with zero expectation that tend to _contribute_ to the variance，我们将增添 specially chosen terms with zero expectation 以减小方差。因此，这是一个控制变量策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更详细地说，the idea is to take advantage of the fact that for any constant $b$, the following identity holds\n",
    "\n",
    "$$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\\nabla_{\\phi}\n",
    "(\\log q_{\\phi}({\\bf z}) \\times b) \\right]=0$$\n",
    "\n",
    "This follows since $q(\\cdot)$ is normalized:\n",
    "\n",
    "$$\\mathbb{E}_{q_{\\phi}({\\bf z})} \\left [\\nabla_{\\phi}\n",
    "\\log q_{\\phi}({\\bf z}) \\right]=\n",
    " \\int \\!d{\\bf z} \\; q_{\\phi}({\\bf z}) \\nabla_{\\phi}\n",
    "\\log q_{\\phi}({\\bf z})=\n",
    " \\int \\! d{\\bf z} \\; \\nabla_{\\phi} q_{\\phi}({\\bf z})=\n",
    "\\nabla_{\\phi} \\int \\! d{\\bf z} \\;  q_{\\phi}({\\bf z})=\\nabla_{\\phi} 1 = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that we can replace any term\n",
    "\n",
    "$$\\log q_{\\phi}({\\bf z}_i) \\overline{f_{\\phi}({\\bf z})} $$\n",
    "\n",
    "in our surrogate objective with\n",
    "\n",
    "$$\\log q_{\\phi}({\\bf z}_i) \\left(\\overline{f_{\\phi}({\\bf z})}-b\\right) $$\n",
    "\n",
    "Doing so doesn't affect the mean of our gradient estimator but it does affect the variance. If we choose $b$ wisely, we can hope to reduce the variance. 实际上，$b$ 不必是常数：it can depend on any of the random choices upstream (or sidestream) of ${\\bf z}_i$.\n",
    "\n",
    "现在我们已经了解 Reducing Variance with Data-Dependent Baselines 的相关理论，接下来我们看看具体如何构造和使用 Pyro baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines in Pyro\n",
    "\n",
    "\n",
    "用户可以通过多种方式 instruct Pyro to use baselines in the context of stochastic variational inference. Since baselines can be attached to any non-reparameterizable random variable, the current baseline interface is at the level of the `pyro.sample` statement. In particular the baseline interface makes use of an argument `baseline`, which is a dictionary that specifies baseline options. \n",
    "请注意，仅在 `guide` 中（而不是在 `model` 中）specify baselines for sample statements 是有意义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decaying Average Baseline\n",
    "\n",
    "最简单的 baseline 是根据 $\\overline{f_{\\phi}({\\bf z})}$ 的最近样本的running average 构建的。在 Pyro 中，可以按以下方式调用这种 baseline：\n",
    "\n",
    "```python\n",
    "z = pyro.sample(\"z\", dist.Bernoulli(...), \n",
    "                infer=dict(baseline={'use_decaying_avg_baseline': True,\n",
    "                                     'baseline_beta': 0.95}))\n",
    "```\n",
    "\n",
    "The optional argument `baseline_beta` specifies the decay rate of the decaying average (default value: `0.90`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Baselines \n",
    "\n",
    "在某些情况下，decaying average baseline 效果很好。在其他情况下，using a baseline that depends on upstream randomness is crucial for getting good variance reduction. 构造这样的 baseline 的一种有效的方法是使用神经网络 that can be adapted during the course of learning. Pyro提供了两种specify such a baseline 的方法(for an extended example see the [AIR tutorial](air.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the user needs to decide what inputs the baseline is going to consume (e.g. the current datapoint under consideration or the previously sampled random variable). Then the user needs to construct a `nn.Module` that encapsulates the baseline computation. This might look something like\n",
    "\n",
    "```python\n",
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self, dim_input, dim_hidden):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim_input, dim_hidden)\n",
    "        # ... finish initialization ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.linear(x)\n",
    "        # ... do more computations ...\n",
    "        return baseline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, assuming the BaselineNN object `baseline_module` has been initialized somewhere else, in the guide we'll have something like\n",
    "\n",
    "```python\n",
    "def guide(x):  # here x is the current mini-batch of data\n",
    "    pyro.module(\"my_baseline\", baseline_module)\n",
    "    # ... other computations ...\n",
    "    z = pyro.sample(\"z\", dist.Bernoulli(...), \n",
    "                    infer=dict(baseline={'nn_baseline': baseline_module,\n",
    "                                         'nn_baseline_input': x}))\n",
    "```\n",
    "\n",
    "Here the argument `nn_baseline` tells Pyro which `nn.Module` to use to construct the baseline. On the backend the argument `nn_baseline_input` is fed into the forward method of the module to compute the baseline $b$. Note that the baseline module needs to be registered with Pyro with a `pyro.module` call so that Pyro is aware of the trainable parameters within the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood Pyro constructs a loss of the form \n",
    "\n",
    "$${\\rm baseline\\; loss} \\equiv\\left(\\overline{f_{\\phi}({\\bf z})} - b  \\right)^2$$\n",
    "\n",
    "which is used to adapt the parameters of the neural network. 没有定理表明这是在这种情况下使用的最佳损失函数(it's not)，但实际上它可以很好地工作。 Just as for the decaying average baseline, the idea is that a baseline that can track the mean $\\overline{f_{\\phi}({\\bf z})}$ will help reduce the variance. Under the hood `SVI` takes one step on the baseline loss in conjunction with a step on the ELBO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在实践中，使用不同的学习超参数集可能很重要(e.g. a higher learning rate) for baseline parameters. In Pyro this can be done as follows:\n",
    "\n",
    "```python\n",
    "def per_param_args(module_name, param_name):\n",
    "    if 'baseline' in param_name or 'baseline' in module_name:\n",
    "        return {\"lr\": 0.010}\n",
    "    else:\n",
    "        return {\"lr\": 0.001}\n",
    "    \n",
    "optimizer = optim.Adam(per_param_args)\n",
    "```\n",
    "\n",
    "请注意，为了使整个过程正确，应仅通过 baseline 损失来优化 baseline 参数。同样，`model` 和 `guide` 参数只能通过ELBO进行优化。 To ensure that this is the case under the hood `SVI` detaches the baseline $b$ that enters the ELBO from the autograd graph.  Also, since the inputs to the neural baseline may depend on the parameters of the model and guide, the inputs are also detached from the autograd graph before they are fed into the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，还有一种供用户 specify a neural baseline 的替代方法。只需使用参数  `baseline_value`:\n",
    "\n",
    "```python\n",
    "b = # do baseline computation\n",
    "z = pyro.sample(\"z\", dist.Bernoulli(...), \n",
    "                infer=dict(baseline={'baseline_value': b}))\n",
    "```\n",
    "\n",
    "This works as above, except in this case it's the user's responsibility to make sure that any autograd tape connecting $b$ to the parameters of the model and guide has been cut. Or to say the same thing in language more familiar to PyTorch users, any inputs to $b$ that depend on $\\theta$ or $\\phi$ need to be detached from the autograd graph with `detach()` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 端对端 Baseline 例子\n",
    "\n",
    "回想一下，在[第一个SVI教程](svi_part_i.ipynb)中，我们考虑了掷硬币的bernoulli-beta 模型。 因为 beta 随机变量不可重参数化(or rather not easily reparameterizable)，相应的 ELBO 梯度 can be quite noisy. In that context we dealt with this problem by using a Beta distribution that provides (approximate) reparameterized gradients. \n",
    "在这里，我们展示了简单的 decaying average baseline 如何减少方差in the case where the Beta distribution is treated as non-reparameterized (so that the ELBO gradient estimator is of the score function type). 在此过程中，我们还使用 `plate` 以完全向量化的方式编写模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与直接比较梯度方差不同，我们将了解SVI收敛需要多少步骤。Recall that for this particular model (because of conjugacy) we can compute the exact posterior. So to assess the utility of baselines in this context, 我们设置了以下简单实验. \n",
    "\n",
    "We initialize the guide at a specified set of variational parameters. We then do SVI until the variational parameters have gotten to within a fixed tolerance of the parameters of the exact posterior. We do this both with and without the decaying average baseline.然后，我们比较两种情况下所需的梯度步数。下面是完整的代码："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(_Since apart from the use of_ `plate` _and_ `use_decaying_avg_baseline`, _this code is very similar to the code in parts I and II of the SVI tutorial, we're not going to go through the code line by line._ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     67
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing inference with use_decaying_avg_baseline=True\n",
      ".\n",
      "Did 84 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7989 & 0.7734\n",
      "Doing inference with use_decaying_avg_baseline=False\n",
      "..\n",
      "Did 194 steps of inference.\n",
      "Final absolute errors for the two variational parameters were 0.7989 & 0.7394\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.distributions.constraints as constraints\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "# Pyro also has a reparameterized Beta distribution so we import\n",
    "# the non-reparameterized version to make our point\n",
    "from pyro.distributions.testing.fakes import NonreparameterizedBeta\n",
    "import pyro.optim as optim\n",
    "from pyro.infer import SVI, TraceGraph_ELBO\n",
    "import sys\n",
    "\n",
    "# enable validation (e.g. validate parameters of distributions)\n",
    "assert pyro.__version__.startswith('1.3.0')\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "smoke_test = ('CI' in os.environ)\n",
    "max_steps = 2 if smoke_test else 10000\n",
    "\n",
    "\n",
    "def param_abs_error(name, target):\n",
    "    return torch.sum(torch.abs(target - pyro.param(name))).item()\n",
    "\n",
    "\n",
    "class BernoulliBetaExample:\n",
    "    def __init__(self, max_steps):\n",
    "        # the maximum number of inference steps we do\n",
    "        self.max_steps = max_steps\n",
    "        # the two hyperparameters for the beta prior\n",
    "        self.alpha0 = 10.0\n",
    "        self.beta0 = 10.0\n",
    "        # the dataset consists of six 1s and four 0s\n",
    "        self.data = torch.zeros(10)\n",
    "        self.data[0:6] = torch.ones(6)\n",
    "        self.n_data = self.data.size(0)\n",
    "        # compute the alpha parameter of the exact beta posterior\n",
    "        self.alpha_n = self.data.sum() + self.alpha0\n",
    "        # compute the beta parameter of the exact beta posterior\n",
    "        self.beta_n = - self.data.sum() + torch.tensor(self.beta0 + self.n_data)\n",
    "        # initial values of the two variational parameters\n",
    "        self.alpha_q_0 = 15.0\n",
    "        self.beta_q_0 = 15.0\n",
    "\n",
    "    def model(self, use_decaying_avg_baseline):\n",
    "        # sample `latent_fairness` from the beta prior\n",
    "        f = pyro.sample(\"latent_fairness\", dist.Beta(self.alpha0, self.beta0))\n",
    "        # use plate to indicate that the observations are\n",
    "        # conditionally independent given f and get vectorization\n",
    "        with pyro.plate(\"data_plate\"):\n",
    "            # observe all ten datapoints using the bernoulli likelihood\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(f), obs=self.data)\n",
    "\n",
    "    def guide(self, use_decaying_avg_baseline):\n",
    "        # register the two variational parameters with pyro\n",
    "        alpha_q = pyro.param(\"alpha_q\", torch.tensor(self.alpha_q_0),\n",
    "                             constraint=constraints.positive)\n",
    "        beta_q = pyro.param(\"beta_q\", torch.tensor(self.beta_q_0),\n",
    "                            constraint=constraints.positive)\n",
    "        # sample f from the beta variational distribution\n",
    "        baseline_dict = {'use_decaying_avg_baseline': use_decaying_avg_baseline,\n",
    "                         'baseline_beta': 0.90}\n",
    "        # note that the baseline_dict specifies whether we're using\n",
    "        # decaying average baselines or not\n",
    "        pyro.sample(\"latent_fairness\", NonreparameterizedBeta(alpha_q, beta_q),\n",
    "                    infer=dict(baseline=baseline_dict))\n",
    "\n",
    "    def do_inference(self, use_decaying_avg_baseline, tolerance=0.80):\n",
    "        # clear the param store in case we're in a REPL\n",
    "        pyro.clear_param_store()\n",
    "        # setup the optimizer and the inference algorithm\n",
    "        optimizer = optim.Adam({\"lr\": .0005, \"betas\": (0.93, 0.999)})\n",
    "        svi = SVI(self.model, self.guide, optimizer, loss=TraceGraph_ELBO())\n",
    "        print(\"Doing inference with use_decaying_avg_baseline=%s\" % use_decaying_avg_baseline)\n",
    "\n",
    "        # do up to this many steps of inference\n",
    "        for k in range(self.max_steps):\n",
    "            svi.step(use_decaying_avg_baseline)\n",
    "            if k % 100 == 0:\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            # compute the distance to the parameters of the true posterior\n",
    "            alpha_error = param_abs_error(\"alpha_q\", self.alpha_n)\n",
    "            beta_error = param_abs_error(\"beta_q\", self.beta_n)\n",
    "\n",
    "            # stop inference early if we're close to the true posterior\n",
    "            if alpha_error < tolerance and beta_error < tolerance:\n",
    "                break\n",
    "\n",
    "        print(\"\\nDid %d steps of inference.\" % k)\n",
    "        print((\"Final absolute errors for the two variational parameters \" +\n",
    "               \"were %.4f & %.4f\") % (alpha_error, beta_error))\n",
    "\n",
    "# do the experiment\n",
    "bbe = BernoulliBetaExample(max_steps=max_steps)\n",
    "bbe.do_inference(use_decaying_avg_baseline=True)\n",
    "bbe.do_inference(use_decaying_avg_baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample output:**\n",
    "```\n",
    "Doing inference with use_decaying_avg_baseline=True\n",
    "....................\n",
    "Did 1932 steps of inference.\n",
    "Final absolute errors for the two variational parameters were 0.7997 & 0.0800\n",
    "Doing inference with use_decaying_avg_baseline=False\n",
    "..................................................\n",
    "Did 4908 steps of inference.\n",
    "Final absolute errors for the two variational parameters were 0.7991 & 0.2532\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于此次运行，我们可以看到 baselines 将我们需要执行的SVI步骤数量大致减少了一半。结果是随机的，并且每次运行都会有所不同，但这是令人鼓舞的结果。这是一个非常人造的示例，但是对于某些 `model` and `guide` 对，baselines 可以带来巨大的成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "[1] `Automated Variational Inference in Probabilistic Programming`,\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "David Wingate, Theo Weber\n",
    "\n",
    "[2] `Black Box Variational Inference`,<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Rajesh Ranganath, Sean Gerrish, David M. Blei\n",
    "\n",
    "[3] `Auto-Encoding Variational Bayes`,<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Diederik P Kingma, Max Welling\n",
    "\n",
    "[4] `Gradient Estimation Using Stochastic Computation Graphs`,\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    John Schulman, Nicolas Heess, Theophane Weber, Pieter Abbeel\n",
    "    \n",
    "[5] `Deep Amortized Inference for Probabilistic Programs`\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Daniel Ritchie, Paul Horsfall, Noah D. Goodman\n",
    "\n",
    "[6] `Neural Variational Inference and Learning in Belief Networks`\n",
    "<br/>&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "Andriy Mnih, Karol Gregor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
