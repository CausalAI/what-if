

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>贝叶斯回归- Introduction (Part 1) &mdash; Pyro Tutorials 编译 1.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="贝叶斯回归-推断算法(Part 2)" href="bayesian_regression_ii.html" />
    <link rel="prev" title="变分自编码器" href="vae.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro 模型介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Pyro 推断简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: Pyro 随机变分推断基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: 条件独立, 子采样和 Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Tensor shapes in Pyro</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">自定义 SVI 目标函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Pyro 模型中使用 PyTorch JIT Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: Pyro 中使用 Effect Handlers 编程手册</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vae.html">变分自编码器</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">贝叶斯回归- Introduction (Part 1)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Tutorial-Outline">Tutorial Outline</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Setup">Setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Dataset">Dataset</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Linear-Regression">Linear Regression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Training-with-PyTorch-Optimizers">Training with PyTorch Optimizers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Plotting-the-Regression-Fit">Plotting the Regression Fit</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Bayesian-Regression-with-Pyro’s-Stochastic-Variational-Inference-(SVI)">Bayesian Regression with Pyro’s Stochastic Variational Inference (SVI)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Model">Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Using-an-AutoGuide">Using an AutoGuide</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Optimizing-the-Evidence-Lower-Bound">Optimizing the Evidence Lower Bound</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Model-Evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Model-Serving-via-TorchScript">Model Serving via TorchScript</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#参考文献">参考文献</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">贝叶斯回归-推断算法(Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">深马尔可夫模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">半监督 VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">随机波动率的 Levy 稳定分布模型</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributed:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="elections.html">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a></li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting Black Box Variational Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Hidden Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Latent Dirichlet Allocation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Deep Kernel Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Gaussian Process Time Series Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Sequential Monte Carlo Filtering</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials 编译</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>贝叶斯回归- Introduction (Part 1)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/bayesian_regression.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="贝叶斯回归--Introduction-(Part-1)">
<h1>贝叶斯回归- Introduction (Part 1)<a class="headerlink" href="#贝叶斯回归--Introduction-(Part-1)" title="Permalink to this headline">¶</a></h1>
<p>回归是机器学习中最常见和最基本的监督学习任务之一。 Suppose we’re given a dataset <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> of the form</p>
<div class="math notranslate nohighlight">
\[\mathcal{D}  = \{ (X_i, y_i) \} \qquad \text{for}\qquad i=1,2,...,N\]</div>
<p>The goal of linear regression is to fit a function to the data of the form:</p>
<div class="math notranslate nohighlight">
\[y = w X + b + \epsilon\]</div>
<p>where <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are learnable parameters and <span class="math notranslate nohighlight">\(\epsilon\)</span> represents observation noise. Specifically <span class="math notranslate nohighlight">\(w\)</span> is a matrix of weights and <span class="math notranslate nohighlight">\(b\)</span> is a bias vector.</p>
<p>在本教程中，我们将首先在 PyTorch 中实现线性回归，并学习参数 <span class="math notranslate nohighlight">\(w\)</span> 和 <span class="math notranslate nohighlight">\(b\)</span> 的点估计。Then we will see how to incorporate uncertainty into our estimates by using Pyro to implement Bayesian regression. 此外，我们将学习 how to use the Pyro’s utility functions to do predictions and serve our model using <code class="docutils literal notranslate"><span class="pre">TorchScript</span></code>.</p>
<div class="section" id="Tutorial-Outline">
<h2>Tutorial Outline<a class="headerlink" href="#Tutorial-Outline" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="#Setup">Setup</a></p></li>
<li><p><a class="reference external" href="#Linear-Regression">Linear Regression</a></p>
<ul>
<li><p><a class="reference external" href="#Training-with-PyTorch-Optimizers">Training with PyTorch Optimizers</a></p></li>
<li><p><a class="reference external" href="#Plotting-the-Regression-Fit">Regression Fit</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#Bayesian-Regression-with-Pyro's-Stochastic-Variational-Inference-%28SVI%29">Bayesian Regression with Pyro’s SVI</a></p>
<ul>
<li><p><a class="reference external" href="#Model">Model</a></p></li>
<li><p><a class="reference external" href="#Using-an-AutoGuide">Using an AutoGuide</a></p></li>
<li><p><a class="reference external" href="#Optimizing-the-Evidence-Lower-Bound">Optimizing the Evidence Lower Bound</a></p></li>
</ul>
</li>
<li><p><a class="reference external" href="#Model-Evaluation">Model Evaluation</a></p></li>
<li><p><a class="reference external" href="#Model-Serving-via-TorchScript">Serving the Model using TorchScript</a></p></li>
</ul>
</div>
<div class="section" id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this headline">¶</a></h2>
<p>Let’s begin by importing the modules we’ll need.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">reset</span> -s -f
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="c1"># for CI testing</span>
<span class="n">smoke_test</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;CI&#39;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">pyro</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;1.3.0&#39;</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">set_rng_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">enable_validation</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># Set matplotlib settings</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Dataset">
<h3>Dataset<a class="headerlink" href="#Dataset" title="Permalink to this headline">¶</a></h3>
<p>The following example is adapted from [1]. We would like to explore the relationship between topographic heterogeneity of a nation as measured by the Terrain Ruggedness Index (variable <em>rugged</em> in the dataset) and its GDP per capita. In particular, it was noted by the authors in [2] that terrain ruggedness or bad geography is related to poorer economic performance outside of Africa, but rugged terrains have had a reverse effect on income for African nations. Let us look at the data and
investigate this relationship. We will be focusing on three features from the dataset: - <code class="docutils literal notranslate"><span class="pre">rugged</span></code>: quantifies the Terrain Ruggedness Index - <code class="docutils literal notranslate"><span class="pre">cont_africa</span></code>: whether the given nation is in Africa - <code class="docutils literal notranslate"><span class="pre">rgdppc_2000</span></code>: Real GDP per capita for the year 2000</p>
<p>The response variable GDP is highly skewed, so we will log-transform it.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">DATA_URL</span> <span class="o">=</span> <span class="s2">&quot;https://d2hg8soec8ck9v.cloudfront.net/datasets/rugged_data.csv&quot;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_URL</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;ISO-8859-1&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">,</span> <span class="s2">&quot;rugged&quot;</span><span class="p">,</span> <span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">]]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">rgdppc_2000</span><span class="p">)]</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">african_nations</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">non_african_nations</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
            <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">],</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Non African Nations&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
                <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">],</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;African Nations&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_8_0.png" src="_images/bayesian_regression_8_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="Linear-Regression">
<h2>Linear Regression<a class="headerlink" href="#Linear-Regression" title="Permalink to this headline">¶</a></h2>
<p>We would like to predict log GDP per capita of a nation as a function of two features from the dataset - whether the nation is in Africa, and its Terrain Ruggedness Index. We will create a trivial class called <code class="docutils literal notranslate"><span class="pre">PyroModule[nn.Linear]</span></code> that subclasses <a class="reference external" href="http://docs.pyro.ai/en/dev/nn.html#module-pyro.nn.module">PyroModule</a> and <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code>. <code class="docutils literal notranslate"><span class="pre">PyroModule</span></code> is very similar to PyTorch’s <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>, but additionally supports <a class="reference external" href="http://docs.pyro.ai/en/dev/primitives.html#primitives">Pyro
primitives</a> as attributes that can be modified by Pyro’s <a class="reference external" href="http://pyro.ai/examples/effect_handlers.html">effect handlers</a> (see the <a class="reference external" href="#Model">next section</a> on how we can have module attributes that are <code class="docutils literal notranslate"><span class="pre">pyro.sample</span></code> primitives). Some general notes:</p>
<ul class="simple">
<li><p>Learnable parameters in PyTorch modules are instances of <code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code>, in this case the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> parameters of the <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> class. When declared inside a <code class="docutils literal notranslate"><span class="pre">PyroModule</span></code> as attributes, these are automatically registered in Pyro’s param store. While this model does not require us to constrain the value of these parameters during optimization, this can also be easily achieved in <code class="docutils literal notranslate"><span class="pre">PyroModule</span></code> using the
<a class="reference external" href="http://docs.pyro.ai/en/dev/nn.html#pyro.nn.module.PyroParam">PyroParam</a> statement.</p></li>
<li><p>Note that while the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of <code class="docutils literal notranslate"><span class="pre">PyroModule[nn.Linear]</span></code> inherits from <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>, it can also be easily overridden. e.g. in the case of logistic regression, we apply a sigmoid transformation to the linear predictor.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">pyro.nn</span> <span class="k">import</span> <span class="n">PyroModule</span>

<span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">],</span> <span class="n">PyroModule</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="Training-with-PyTorch-Optimizers">
<h3>Training with PyTorch Optimizers<a class="headerlink" href="#Training-with-PyTorch-Optimizers" title="Permalink to this headline">¶</a></h3>
<p>Note that in addition to the two features <code class="docutils literal notranslate"><span class="pre">rugged</span></code> and <code class="docutils literal notranslate"><span class="pre">cont_africa</span></code>, we also include an interaction term in our model, which lets us separately model the effect of ruggedness on the GDP for nations within and outside Africa.</p>
<p>We use the mean squared error (MSE) as our loss and Adam as our optimizer from the <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> module. We would like to optimize the parameters of our model, namely the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> parameters of the network, which corresponds to our regression coefficents and the intercept.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Dataset: Add a feature to capture the interaction between &quot;cont_africa&quot; and &quot;rugged&quot;</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;cont_africa_x_rugged&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">,</span> <span class="s2">&quot;rugged&quot;</span><span class="p">,</span> <span class="s2">&quot;cont_africa_x_rugged&quot;</span><span class="p">,</span> <span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Regression model</span>
<span class="n">linear_reg_model</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Define loss and optimize</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">linear_reg_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1500</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">smoke_test</span> <span class="k">else</span> <span class="mi">2</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="c1"># run the model forward on the data</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_reg_model</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># calculate the mse loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
    <span class="c1"># initialize gradients to zero</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># backpropagate</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># take a gradient step</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span>

<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[iteration </span><span class="si">%04d</span><span class="s2">] loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>


<span class="c1"># Inspect learned parameters</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learned parameters:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">linear_reg_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[iteration 0050] loss: 3179.7852
[iteration 0100] loss: 1616.1371
[iteration 0150] loss: 1109.4117
[iteration 0200] loss: 833.7545
[iteration 0250] loss: 637.5822
[iteration 0300] loss: 488.2652
[iteration 0350] loss: 376.4650
[iteration 0400] loss: 296.0483
[iteration 0450] loss: 240.6140
[iteration 0500] loss: 203.9386
[iteration 0550] loss: 180.6171
[iteration 0600] loss: 166.3493
[iteration 0650] loss: 157.9457
[iteration 0700] loss: 153.1786
[iteration 0750] loss: 150.5735
[iteration 0800] loss: 149.2020
[iteration 0850] loss: 148.5065
[iteration 0900] loss: 148.1668
[iteration 0950] loss: 148.0070
[iteration 1000] loss: 147.9347
[iteration 1050] loss: 147.9032
[iteration 1100] loss: 147.8900
[iteration 1150] loss: 147.8847
[iteration 1200] loss: 147.8827
[iteration 1250] loss: 147.8819
[iteration 1300] loss: 147.8817
[iteration 1350] loss: 147.8816
[iteration 1400] loss: 147.8815
[iteration 1450] loss: 147.8815
[iteration 1500] loss: 147.8815
Learned parameters:
weight [[-1.9478593  -0.20278624  0.39330274]]
bias [9.22308]
</pre></div></div>
</div>
</div>
<div class="section" id="Plotting-the-Regression-Fit">
<h3>Plotting the Regression Fit<a class="headerlink" href="#Plotting-the-Regression-Fit" title="Permalink to this headline">¶</a></h3>
<p>Let us plot the regression fit for our model, separately for countries outside and within Africa.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fit</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">fit</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">linear_reg_model</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">african_nations</span> <span class="o">=</span> <span class="n">fit</span><span class="p">[</span><span class="n">fit</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">non_african_nations</span> <span class="o">=</span> <span class="n">fit</span><span class="p">[</span><span class="n">fit</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Regression Fit&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span> <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">],</span> <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span> <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Non African Nations&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span> <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rgdppc_2000&quot;</span><span class="p">],</span> <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span> <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;African Nations&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_14_0.png" src="_images/bayesian_regression_14_0.png" />
</div>
</div>
<p>We notice that the relationship between terrain ruggedness has an inverse relationship with GDP for non-African nations, but it positively affects the GDP for African nations. It is however unclear how robust this trend is. In particular, we would like to understand how the regression fit would vary due to parameter uncertainty. To address this, we will build a simple bayesian model for linear regression. <a class="reference external" href="http://mlg.eng.cam.ac.uk/zoubin/papers/NatureReprint15.pdf">Bayesian modeling</a> offers a
systematic framework for reasoning about model uncertainty. Instead of just learning point estimates, we’re going to learn a <em>distribution</em> over parameters that are consistent with the observed data.</p>
</div>
</div>
<div class="section" id="Bayesian-Regression-with-Pyro’s-Stochastic-Variational-Inference-(SVI)">
<h2>Bayesian Regression with Pyro’s Stochastic Variational Inference (SVI)<a class="headerlink" href="#Bayesian-Regression-with-Pyro’s-Stochastic-Variational-Inference-(SVI)" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Model">
<h3>Model<a class="headerlink" href="#Model" title="Permalink to this headline">¶</a></h3>
<p>In order to make our linear regression Bayesian, we need to put priors on the parameters <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. These are distributions that represent our prior belief about reasonable values for <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span> (before observing any data).</p>
<p>Making a Bayesian model for linear regression is very intuitive using <code class="docutils literal notranslate"><span class="pre">PyroModule</span></code> as earlier. Note the following:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">BayesianRegression</span></code> module internally uses the same <code class="docutils literal notranslate"><span class="pre">PyroModule[nn.Linear]</span></code> module. However, note that we replace the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and the <code class="docutils literal notranslate"><span class="pre">bias</span></code> of the this module with <code class="docutils literal notranslate"><span class="pre">PyroSample</span></code> statements. These statements allow us to place a prior over the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> parameters, instead of treating them as fixed learnable parameters. For the bias component, we set a reasonably wide prior since it is likely to be substantially above 0.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">BayesianRegression.forward</span></code> method specifies the generative process. We generate the mean value of the response by calling the <code class="docutils literal notranslate"><span class="pre">linear</span></code> module (which, as you saw, samples the <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code> parameters from the prior and returns a value for the mean response). Finally we use the <code class="docutils literal notranslate"><span class="pre">obs</span></code> argument to the <code class="docutils literal notranslate"><span class="pre">pyro.sample</span></code> statement to condition on the observed data <code class="docutils literal notranslate"><span class="pre">y_data</span></code> with a learned observation noise <code class="docutils literal notranslate"><span class="pre">sigma</span></code>. The model returns the regression line given by the variable
<code class="docutils literal notranslate"><span class="pre">mean</span></code>.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.nn</span> <span class="k">import</span> <span class="n">PyroSample</span>


<span class="k">class</span> <span class="nc">BayesianRegression</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">([</span><span class="n">out_features</span><span class="p">])</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Using-an-AutoGuide">
<h3>Using an AutoGuide<a class="headerlink" href="#Using-an-AutoGuide" title="Permalink to this headline">¶</a></h3>
<p>In order to do inference, i.e. learn the posterior distribution over our unobserved parameters, we will use Stochastic Variational Inference (SVI). The guide determines a family of distributions, and <code class="docutils literal notranslate"><span class="pre">SVI</span></code> aims to find an approximate posterior distribution from this family that has the lowest KL divergence from the true posterior.</p>
<p>Users can write arbitrarily flexible custom guides in Pyro, but in this tutorial, we will restrict ourselves to Pyro’s <a class="reference external" href="http://docs.pyro.ai/en/dev/infer.autoguide.html">autoguide library</a>. In the next <a class="reference internal" href="bayesian_regression_ii.html"><span class="doc">tutorial</span></a>, we will explore how to write guides by hand.</p>
<p>To begin with, we will use the <code class="docutils literal notranslate"><span class="pre">AutoDiagonalNormal</span></code> guide that models the distribution of unobserved parameters in the model as a Gaussian with diagonal covariance, i.e. it assumes that there is no correlation amongst the latent variables (quite a strong modeling assumption as we shall see in <a class="reference internal" href="bayesian_regression_ii.html"><span class="doc">Part II</span></a>). Under the hood, this defines a <code class="docutils literal notranslate"><span class="pre">guide</span></code> that uses a <code class="docutils literal notranslate"><span class="pre">Normal</span></code> distribution with learnable parameters corresponding to each <code class="docutils literal notranslate"><span class="pre">sample</span></code> statement in the model.
e.g. in our case, this distribution should have a size of <code class="docutils literal notranslate"><span class="pre">(5,)</span></code> correspoding to the 3 regression coefficients for each of the terms, and 1 component contributed each by the intercept term and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> in the model.</p>
<p>Autoguide also supports learning MAP estimates with <code class="docutils literal notranslate"><span class="pre">AutoDelta</span></code> or composing guides with <code class="docutils literal notranslate"><span class="pre">AutoGuideList</span></code> (see the <a class="reference external" href="http://docs.pyro.ai/en/dev/infer.autoguide.html">docs</a> for more information).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.infer.autoguide</span> <span class="k">import</span> <span class="n">AutoDiagonalNormal</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BayesianRegression</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">guide</span> <span class="o">=</span> <span class="n">AutoDiagonalNormal</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Optimizing-the-Evidence-Lower-Bound">
<h3>Optimizing the Evidence Lower Bound<a class="headerlink" href="#Optimizing-the-Evidence-Lower-Bound" title="Permalink to this headline">¶</a></h3>
<p>We will use stochastic variational inference (SVI) (for an introduction to SVI, see <a class="reference internal" href="svi_part_i.html"><span class="doc">SVI Part I</span></a>) for doing inference. Just like in the non-Bayesian linear regression model, each iteration of our training loop will take a gradient step, with the difference that in this case, we’ll use the Evidence Lower Bound (ELBO) objective instead of the MSE loss by constructing a <code class="docutils literal notranslate"><span class="pre">Trace_ELBO</span></code> object that we pass to <code class="docutils literal notranslate"><span class="pre">SVI</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="k">import</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">Trace_ELBO</span>


<span class="n">adam</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">})</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span> <span class="n">adam</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>
</pre></div>
</div>
</div>
<p>Note that we use the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> optimizer from Pyro’s <code class="docutils literal notranslate"><span class="pre">optim</span></code> module and not the <code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> module as earlier. Here <code class="docutils literal notranslate"><span class="pre">Adam</span></code> is a thin wrapper around <code class="docutils literal notranslate"><span class="pre">torch.optim.Adam</span></code> (see <a class="reference internal" href="svi_part_i.html#optimizers"><span class="std std-ref">here</span></a> for a discussion). Optimizers in <code class="docutils literal notranslate"><span class="pre">pyro.optim</span></code> are used to optimize and update parameter values in Pyro’s parameter store. In particular, you will notice that we do not need to pass in learnable parameters to the optimizer since that is determined by the guide code and happens
behind the scenes within the <code class="docutils literal notranslate"><span class="pre">SVI</span></code> class automatically. To take an ELBO gradient step we simply call the step method of SVI. The data argument we pass to <code class="docutils literal notranslate"><span class="pre">SVI.step</span></code> will be passed to both <code class="docutils literal notranslate"><span class="pre">model()</span></code> and <code class="docutils literal notranslate"><span class="pre">guide()</span></code>. The complete training loop is as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="c1"># calculate the loss and take a gradient step</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[iteration </span><span class="si">%04d</span><span class="s2">] loss: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[iteration 0001] loss: 6.2310
[iteration 0101] loss: 3.5253
[iteration 0201] loss: 3.2347
[iteration 0301] loss: 3.0890
[iteration 0401] loss: 2.6377
[iteration 0501] loss: 2.0626
[iteration 0601] loss: 1.4852
[iteration 0701] loss: 1.4631
[iteration 0801] loss: 1.4632
[iteration 0901] loss: 1.4592
[iteration 1001] loss: 1.4940
[iteration 1101] loss: 1.4988
[iteration 1201] loss: 1.4938
[iteration 1301] loss: 1.4679
[iteration 1401] loss: 1.4581
</pre></div></div>
</div>
<p>We can examine the optimized parameter values by fetching from Pyro’s param store.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">guide</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">pyro</span><span class="o">.</span><span class="n">get_param_store</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
AutoDiagonalNormal.loc Parameter containing:
tensor([-2.2371, -1.8097, -0.1691,  0.3791,  9.1823])
AutoDiagonalNormal.scale tensor([0.0551, 0.1142, 0.0387, 0.0769, 0.0702])
</pre></div></div>
</div>
<p>As you can see, instead of just point estimates, we now have uncertainty estimates (<code class="docutils literal notranslate"><span class="pre">AutoDiagonalNormal.scale</span></code>) for our learned parameters. Note that Autoguide packs the latent variables into a single tensor, in this case, one entry per variable sampled in our model. Both the <code class="docutils literal notranslate"><span class="pre">loc</span></code> and <code class="docutils literal notranslate"><span class="pre">scale</span></code> parameters have size <code class="docutils literal notranslate"><span class="pre">(5,)</span></code>, one for each of the latent variables in the model, as we had remarked earlier.</p>
<p>To look at the distribution of the latent parameters more clearly, we can make use of the <code class="docutils literal notranslate"><span class="pre">AutoDiagonalNormal.quantiles</span></code> method which will unpack the latent samples from the autoguide, and automatically constrain them to the site’s support (e.g. the variable <code class="docutils literal notranslate"><span class="pre">sigma</span></code> must lie in <code class="docutils literal notranslate"><span class="pre">(0,</span> <span class="pre">10)</span></code>). We see that the median values for the parameters are quite close to the Maximum Likelihood point estimates we obtained from our first model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">guide</span><span class="o">.</span><span class="n">quantiles</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;sigma&#39;: [tensor(0.9328), tensor(0.9647), tensor(0.9976)],
 &#39;linear.weight&#39;: [tensor([[-1.8868, -0.1952,  0.3272]]),
  tensor([[-1.8097, -0.1691,  0.3791]]),
  tensor([[-1.7327, -0.1429,  0.4309]])],
 &#39;linear.bias&#39;: [tensor([9.1350]), tensor([9.1823]), tensor([9.2297])]}
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Model-Evaluation">
<h2>Model Evaluation<a class="headerlink" href="#Model-Evaluation" title="Permalink to this headline">¶</a></h2>
<p>To evaluate our model, we’ll generate some predictive samples and look at the posteriors. For this we will make use of the <a class="reference external" href="http://docs.pyro.ai/en/stable/inference_algos.html#pyro.infer.predictive.Predictive">Predictive</a> utility class.</p>
<ul class="simple">
<li><p>We generate 800 samples from our trained model. Internally, this is done by first generating samples for the unobserved sites in the <code class="docutils literal notranslate"><span class="pre">guide</span></code>, and then running the model forward by conditioning the sites to values sampled from the <code class="docutils literal notranslate"><span class="pre">guide</span></code>. Refer to the <a class="reference external" href="#Model-Serving-via-TorchScript">Model Serving</a> section for insight on how the <code class="docutils literal notranslate"><span class="pre">Predictive</span></code> class works.</p></li>
<li><p>Note that in <code class="docutils literal notranslate"><span class="pre">return_sites</span></code>, we specify both the outcome (<code class="docutils literal notranslate"><span class="pre">&quot;obs&quot;</span></code> site) as well as the return value of the model (<code class="docutils literal notranslate"><span class="pre">&quot;_RETURN&quot;</span></code>) which captures the regression line. Additionally, we would also like to capture the regression coefficients (given by <code class="docutils literal notranslate"><span class="pre">&quot;linear.weight&quot;</span></code>) for further analysis.</p></li>
<li><p>The remaining code is simply used to plot the 90% CI for the two variables from our model.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="k">import</span> <span class="n">Predictive</span>


<span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
    <span class="n">site_stats</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">samples</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">site_stats</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="s2">&quot;5%&quot;</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
            <span class="s2">&quot;95%&quot;</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="k">return</span> <span class="n">site_stats</span>


<span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="o">=</span><span class="n">guide</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
                        <span class="n">return_sites</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;linear.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;obs&quot;</span><span class="p">,</span> <span class="s2">&quot;_RETURN&quot;</span><span class="p">))</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
<span class="n">pred_summary</span> <span class="o">=</span> <span class="n">summary</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">mu</span> <span class="o">=</span> <span class="n">pred_summary</span><span class="p">[</span><span class="s2">&quot;_RETURN&quot;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pred_summary</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;cont_africa&quot;</span><span class="p">:</span> <span class="n">x_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;rugged&quot;</span><span class="p">:</span> <span class="n">x_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;mu_mean&quot;</span><span class="p">:</span> <span class="n">mu</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span>
    <span class="s2">&quot;mu_perc_5&quot;</span><span class="p">:</span> <span class="n">mu</span><span class="p">[</span><span class="s2">&quot;5%&quot;</span><span class="p">],</span>
    <span class="s2">&quot;mu_perc_95&quot;</span><span class="p">:</span> <span class="n">mu</span><span class="p">[</span><span class="s2">&quot;95%&quot;</span><span class="p">],</span>
    <span class="s2">&quot;y_mean&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span>
    <span class="s2">&quot;y_perc_5&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="s2">&quot;5%&quot;</span><span class="p">],</span>
    <span class="s2">&quot;y_perc_95&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="s2">&quot;95%&quot;</span><span class="p">],</span>
    <span class="s2">&quot;true_gdp&quot;</span><span class="p">:</span> <span class="n">y_data</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">african_nations</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">non_african_nations</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">predictions</span><span class="p">[</span><span class="s2">&quot;cont_africa&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">african_nations</span> <span class="o">=</span> <span class="n">african_nations</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">])</span>
<span class="n">non_african_nations</span> <span class="o">=</span> <span class="n">non_african_nations</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Regression line 90% CI&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;mu_mean&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
                   <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;mu_perc_5&quot;</span><span class="p">],</span>
                   <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;mu_perc_95&quot;</span><span class="p">],</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;true_gdp&quot;</span><span class="p">],</span>
           <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Non African Nations&quot;</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;mu_mean&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
                   <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;mu_perc_5&quot;</span><span class="p">],</span>
                   <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;mu_perc_95&quot;</span><span class="p">],</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;true_gdp&quot;</span><span class="p">],</span>
           <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;African Nations&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_31_0.png" src="_images/bayesian_regression_31_0.png" />
</div>
</div>
<p>The above figure shows the uncertainty in our estimate of the regression line, and the 90% CI around the mean. We can also see that most of the data points actually lie outside the 90% CI, and this is expected because we have not plotted the outcome variable which will be affected by <code class="docutils literal notranslate"><span class="pre">sigma</span></code>! Let us do so next.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Posterior predictive distribution with 90% CI&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;y_mean&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
                   <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;y_perc_5&quot;</span><span class="p">],</span>
                   <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;y_perc_95&quot;</span><span class="p">],</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">non_african_nations</span><span class="p">[</span><span class="s2">&quot;true_gdp&quot;</span><span class="p">],</span>
           <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Non African Nations&quot;</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">])</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;y_mean&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
                   <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;y_perc_5&quot;</span><span class="p">],</span>
                   <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;y_perc_95&quot;</span><span class="p">],</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;rugged&quot;</span><span class="p">],</span>
           <span class="n">african_nations</span><span class="p">[</span><span class="s2">&quot;true_gdp&quot;</span><span class="p">],</span>
           <span class="s2">&quot;o&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Terrain Ruggedness Index&quot;</span><span class="p">,</span>
          <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;log GDP (2000)&quot;</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s2">&quot;African Nations&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_33_0.png" src="_images/bayesian_regression_33_0.png" />
</div>
</div>
<p>We observe that the outcome from our model and the 90% CI accounts for the majority of the data points that we observe in practice. It is usually a good idea to do such posterior predictive checks to see if our model gives valid predictions.</p>
<p>Finally, let us revisit our earlier question of how robust the relationship between terrain ruggedness and GDP is against any uncertainty in the parameter estimates from our model. For this, we plot the distribution of the slope of the log GDP given terrain ruggedness for nations within and outside Africa. As can be seen below, the probability mass for African nations is largely concentrated in the positive region and vice-versa for other nations, lending further credence to the original
hypothesis.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">weight</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&quot;linear.weight&quot;</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">gamma_within_africa</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">gamma_outside_africa</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">gamma_within_africa</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;African nations&quot;</span><span class="p">},)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">gamma_outside_africa</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Non-African nations&quot;</span><span class="p">})</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Density of Slope : log(GDP) vs. Terrain Ruggedness&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_35_0.png" src="_images/bayesian_regression_35_0.png" />
</div>
</div>
</div>
<div class="section" id="Model-Serving-via-TorchScript">
<h2>Model Serving via TorchScript<a class="headerlink" href="#Model-Serving-via-TorchScript" title="Permalink to this headline">¶</a></h2>
<p>Finally, note that the <code class="docutils literal notranslate"><span class="pre">model</span></code>, <code class="docutils literal notranslate"><span class="pre">guide</span></code> and the <code class="docutils literal notranslate"><span class="pre">Predictive</span></code> utility class are all <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> instances, and can be serialized as <a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a>.</p>
<p>Here, we show how we can serve a Pyro model as a <a class="reference external" href="https://pytorch.org/docs/stable/jit.html#torch.jit.ScriptModule">torch.jit.ModuleScript</a>, which can be run separately as a C++ program without a Python runtime.</p>
<p>To do so, we will rewrite our own simple version of the <code class="docutils literal notranslate"><span class="pre">Predictive</span></code> utility class using Pyro’s <a class="reference external" href="http://pyro.ai/examples/effect_handlers.html">effect handling library</a>. This uses:</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">trace</span></code> poutine to capture the execution trace from running the model/guide code.</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">replay</span></code> poutine to condition the sites in the model to values sampled from the guide trace.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">pyro</span> <span class="k">import</span> <span class="n">poutine</span>
<span class="kn">from</span> <span class="nn">pyro.poutine.util</span> <span class="k">import</span> <span class="n">prune_subsample_sites</span>
<span class="kn">import</span> <span class="nn">warnings</span>


<span class="k">class</span> <span class="nc">Predict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">guide</span> <span class="o">=</span> <span class="n">guide</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">guide_trace</span> <span class="o">=</span> <span class="n">poutine</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guide</span><span class="p">)</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">model_trace</span> <span class="o">=</span> <span class="n">poutine</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">poutine</span><span class="o">.</span><span class="n">replay</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">guide_trace</span><span class="p">))</span><span class="o">.</span><span class="n">get_trace</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">site</span> <span class="ow">in</span> <span class="n">prune_subsample_sites</span><span class="p">(</span><span class="n">model_trace</span><span class="p">)</span><span class="o">.</span><span class="n">stochastic_nodes</span><span class="p">:</span>
            <span class="n">samples</span><span class="p">[</span><span class="n">site</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_trace</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">site</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">v</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

<span class="n">predict_fn</span> <span class="o">=</span> <span class="n">Predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">guide</span><span class="p">)</span>
<span class="n">predict_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace_module</span><span class="p">(</span><span class="n">predict_fn</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">x_data</span><span class="p">,)},</span> <span class="n">check_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We use <a class="reference external" href="https://pytorch.org/docs/stable/jit.html#torch.jit.trace_module">torch.jit.trace_module</a> to trace the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of this module and save it using <a class="reference external" href="https://pytorch.org/docs/stable/jit.html#torch.jit.save">torch.jit.save</a>. This saved model <code class="docutils literal notranslate"><span class="pre">reg_predict.pt</span></code> can be loaded with PyTorch’s C++ API using <code class="docutils literal notranslate"><span class="pre">torch::jit::load(filename)</span></code>, or using the Python API as we do below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">predict_module</span><span class="p">,</span> <span class="s1">&#39;/tmp/reg_predict.pt&#39;</span><span class="p">)</span>
<span class="n">pred_loaded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/reg_predict.pt&#39;</span><span class="p">)</span>
<span class="n">pred_loaded</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([9.2165]),
 tensor([[-1.6612, -0.1498,  0.4282]]),
 tensor([ 7.5951,  8.2473,  9.3864,  9.2590,  9.0540,  9.3915,  8.6764,  9.3775,
          9.5473,  9.6144, 10.3521,  8.5452,  5.4008,  8.4601,  9.6219,  9.7774,
          7.1958,  7.2581,  8.9159,  9.0875,  8.3730,  8.7903,  9.3167,  8.8155,
          7.4433,  9.9981,  8.6909,  9.2915, 10.1376,  7.7618, 10.1916,  7.4754,
          6.3473,  7.7584,  9.1307,  6.0794,  8.5641,  7.8487,  9.2828,  9.0763,
          7.9250, 10.9226,  8.0005, 10.1799,  5.3611,  8.1174,  8.0585,  8.5098,
          6.8656,  8.6765,  7.8925,  9.5233, 10.1269, 10.2661,  7.8883,  8.9194,
         10.2866,  7.0821,  8.2370,  8.3087,  7.8408,  8.4891,  8.0107,  7.6815,
          8.7497,  9.3551,  9.9687, 10.4804,  8.5176,  7.1679, 10.8805,  7.4919,
          8.7088,  9.2417,  9.2360,  9.7907,  8.4934,  7.8897,  9.5338,  9.6572,
          9.6604,  9.9855,  6.7415,  8.1721, 10.0646, 10.0817,  8.4503,  9.2588,
          8.4489,  7.7516,  6.8496,  9.2208,  8.9852, 10.6585,  9.4218,  9.1290,
          9.5631,  9.7422, 10.2814,  7.2624,  9.6727,  8.9743,  6.9666,  9.5856,
          9.2518,  8.4207,  8.6988,  9.1914,  7.8161,  9.8446,  6.5528,  8.5518,
          6.7168,  7.0694,  8.9211,  8.5311,  8.4545, 10.8346,  7.8768,  9.2537,
          9.0776,  9.4698,  7.9611,  9.2177,  8.0880,  8.5090,  9.2262,  8.9242,
          9.3966,  7.5051,  9.1014,  8.9601,  7.7225,  8.7569,  8.5847,  8.8465,
          9.7494,  8.8587,  6.5624,  6.9372,  9.9806, 10.1259,  9.1864,  7.5758,
          9.8258,  8.6375,  7.6954,  8.9718,  7.0985,  8.6360,  8.5951,  8.9163,
          8.4661,  8.4551, 10.6844,  7.5948,  8.7568,  9.5296,  8.9530,  7.1214,
          9.1401,  8.4992,  8.9115, 10.9739,  8.1593, 10.1162,  9.7072,  7.8641,
          8.8606,  7.5935]),
 tensor(0.9631))
</pre></div></div>
</div>
<p>Let us check that our <code class="docutils literal notranslate"><span class="pre">Predict</span></code> module was indeed serialized correctly, by generating samples from the loaded module and regenerating the previous plot.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">weight</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">800</span><span class="p">):</span>
    <span class="c1"># index = 1 corresponds to &quot;linear.weight&quot;</span>
    <span class="n">weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_loaded</span><span class="p">(</span><span class="n">x_data</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">gamma_within_africa</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">gamma_outside_africa</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">gamma_within_africa</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;African nations&quot;</span><span class="p">},)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">gamma_outside_africa</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;Non-African nations&quot;</span><span class="p">})</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Loaded TorchScript Module : log(GDP) vs. Terrain Ruggedness&quot;</span><span class="p">);</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/bayesian_regression_41_0.png" src="_images/bayesian_regression_41_0.png" />
</div>
</div>
<p>In the next section, we’ll look at how to write guides for variational inference as well as compare the results with inference via HMC.</p>
<div class="section" id="参考文献">
<h3>参考文献<a class="headerlink" href="#参考文献" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>McElreath, D., <em>Statistical Rethinking, Chapter 7</em>, 2016</p></li>
<li><p>Nunn, N. &amp; Puga, D., <a class="reference external" href="https://diegopuga.org/papers/rugged.pdf">Ruggedness: The blessing of bad geography in Africa”</a>, Review of Economics and Statistics 94(1), Feb. 2012</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="bayesian_regression_ii.html" class="btn btn-neutral float-right" title="贝叶斯回归-推断算法(Part 2)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="vae.html" class="btn btn-neutral float-left" title="变分自编码器" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Uber Technologies, Inc; 编译 by Heyang Gong

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>