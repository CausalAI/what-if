

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Predicting the outcome of a US presidential election using Bayesian optimal experimental design &mdash; Pyro Tutorials 编译 1.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/pyro.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dirichlet Process Mixture Models in Pyro" href="dirichlet_process_mixture.html" />
    <link rel="prev" title="Designing Adaptive Experiments to Study Working Memory" href="working_memory.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pyro_logo_wide.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Introduction:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_part_i.html">Pyro 模型介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro_part_ii.html">Pyro 推断简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_i.html">SVI Part I: Pyro 随机变分推断基础</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_ii.html">SVI Part II: 条件独立, 子采样和 Amortization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svi_part_iii.html">SVI Part III: ELBO Gradient Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_shapes.html">Tensor shapes in Pyro</a></li>
</ul>
<p class="caption"><span class="caption-text">Advanced:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="enumeration.html">Inference with Discrete Latent Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_objectives.html">自定义 SVI 目标函数</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">Pyro 模型中使用 PyTorch JIT Compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="minipyro.html">Mini-Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="effect_handlers.html">Poutine: Pyro 中使用 Effect Handlers 编程手册</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vae.html">变分自编码器</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression.html">贝叶斯回归- Introduction (Part 1)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayesian_regression_ii.html">贝叶斯回归-推断算法(Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dmm.html">深马尔可夫模型</a></li>
<li class="toctree-l1"><a class="reference internal" href="air.html">Attend Infer Repeat</a></li>
<li class="toctree-l1"><a class="reference internal" href="ss-vae.html">半监督 VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="stable.html">随机波动率的 Levy 稳定分布模型</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributed:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="gmm.html">Gaussian Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp.html">Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gplvm.html">Gaussian Process Latent Variable Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="bo.html">Bayesian Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="easyguide.html">Writing guides using EasyGuide</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_i.html">Forecasting I: univariate, heavy tailed</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_ii.html">Forecasting II: state space models</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecasting_iii.html">Forecasting III: hierarchical models</a></li>
<li class="toctree-l1"><a class="reference internal" href="tracking_1d.html">Tracking an Unknown Number of Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="csis.html">Compiled Sequential Importance Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-implicature.html">The Rational Speech Act framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="RSA-hyperbole.html">Understanding Hyperbole using RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="ekf.html">Kalman Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="working_memory.html">Designing Adaptive Experiments to Study Working Memory</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Predicting the outcome of a US presidential election using Bayesian optimal experimental design</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Choosing-a-prior">Choosing a prior</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Setting-up-the-model">Setting up the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Understanding-the-prior">Understanding the prior</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Measuring-the-expected-information-gain-of-a-polling-strategy">Measuring the expected information gain of a polling strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Variational-estimators-of-EIG">Variational estimators of EIG</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Running-the-experiment">Running the experiment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Analysing-the-data">Analysing the data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Conclusions">Conclusions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dirichlet_process_mixture.html">Dirichlet Process Mixture Models in Pyro</a></li>
<li class="toctree-l1"><a class="reference internal" href="boosting_bbvi.html">Boosting Black Box Variational Inference</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="capture_recapture.html">Capture-Recapture Models (CJS Models)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cevae.html">Causal Effect VAE</a></li>
<li class="toctree-l1"><a class="reference internal" href="hmm.html">Hidden Markov Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="lda.html">Latent Dirichlet Allocation</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">Markov Chain Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="neutra.html">NeuTraReparam</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_gamma.html">Sparse Gamma Deep Exponential Family</a></li>
<li class="toctree-l1"><a class="reference internal" href="dkl.html">Deep Kernel Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="einsum.html">Plated Einsum</a></li>
<li class="toctree-l1"><a class="reference internal" href="forecast_simple.html">Multivariate Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="timeseries.html">Gaussian Process Time Series Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="smcfilter.html">Sequential Monte Carlo Filtering</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Pyro Tutorials 编译</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Predicting the outcome of a US presidential election using Bayesian optimal experimental design</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/elections.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Predicting-the-outcome-of-a-US-presidential-election-using-Bayesian-optimal-experimental-design">
<h1>Predicting the outcome of a US presidential election using Bayesian optimal experimental design<a class="headerlink" href="#Predicting-the-outcome-of-a-US-presidential-election-using-Bayesian-optimal-experimental-design" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we explore the use of optimal experimental design techniques to create an optimal polling strategy to predict the outcome of a US presidential election. In a <a class="reference external" href="http://pyro.ai/examples/working_memory.html">previous tutorial</a>, we explored the use of Bayesian optimal experimental design to learn the working memory capacity of a single person. Here, we apply the same concepts to study a whole country.</p>
<p>To begin, we need a Bayesian model of the winner of the election <code class="docutils literal notranslate"><span class="pre">w</span></code>, as well as the outcome <code class="docutils literal notranslate"><span class="pre">y</span></code> of any poll we may plan to conduct. The experimental design is the number of people <span class="math notranslate nohighlight">\(n_i\)</span> to poll in each state. To set up our exploratory model, we are going to make a number of simplifying assumptions. We will use historical election data 1976-2012 to construct a plausible prior and the 2016 election as our test set: we imagine that we are conducting polling just before the 2016 election.</p>
<div class="section" id="Choosing-a-prior">
<h2>Choosing a prior<a class="headerlink" href="#Choosing-a-prior" title="Permalink to this headline">¶</a></h2>
<p>In our model, we include a 51 dimensional latent variabe <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. For each of the 50 states plus DC we define</p>
<div class="math notranslate nohighlight">
\[\alpha_i = \text{logit }\mathbb{P}(\text{a random voter in state } i \text{ votes Democrat in the 2016 election})\]</div>
<p>and we assume all other voters vote Republican. Right before the election, the value of <span class="math notranslate nohighlight">\(\alpha\)</span> is unknown and we wish to estimate it by conducting a poll with <span class="math notranslate nohighlight">\(n_i\)</span> people in state <span class="math notranslate nohighlight">\(i\)</span> for <span class="math notranslate nohighlight">\(i=1, ..., 51\)</span> . The winner <span class="math notranslate nohighlight">\(w\)</span> of the election is decided by the Electoral College system. The number of electoral college votes gained by the Democrats in state <span class="math notranslate nohighlight">\(i\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}e_i =  \begin{cases}
k_i \text{ if } \alpha_i &gt; \frac{1}{2} \\
0 \text{ otherwise}
\end{cases}\end{split}\]</div>
<p>(this is a rough approximation of the true system). All other electoral college votes go to the Republicans. Here <span class="math notranslate nohighlight">\(k_i\)</span> is the number of electoral college votes alloted to state <span class="math notranslate nohighlight">\(i\)</span>, which are listed in the following data frame.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Data path</span>
<span class="n">BASE_URL</span> <span class="o">=</span>  <span class="s2">&quot;https://d2hg8soec8ck9v.cloudfront.net/datasets/us_elections/&quot;</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlopen</span>

<span class="n">electoral_college_votes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">urlopen</span><span class="p">(</span><span class="n">BASE_URL</span> <span class="o">+</span> <span class="s2">&quot;electoral_college_votes.pickle&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">electoral_college_votes</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">ec_votes_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">electoral_college_votes</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
       Electoral college votes
State
AL                           9
AK                           3
AZ                          11
AR                           6
CA                          55
</pre></div></div>
</div>
<p>The winner <span class="math notranslate nohighlight">\(w\)</span> of the election is</p>
<div class="math notranslate nohighlight">
\[\begin{split} w = \begin{cases}
\text{Democrats if } \sum_i e_i &gt; \frac{1}{2}\sum_i k_i  \\
\text{Republicans otherwise}
\end{cases}\end{split}\]</div>
<p>In code, this is expressed as follows</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">election_winner</span><span class="p">(</span><span class="n">alpha</span><span class="p">):</span>
    <span class="n">dem_win_state</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha</span> <span class="o">&gt;</span> <span class="mf">0.</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">dem_electoral_college_votes</span> <span class="o">=</span> <span class="n">ec_votes_tensor</span> <span class="o">*</span> <span class="n">dem_win_state</span>
    <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="n">dem_electoral_college_votes</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">ec_votes_tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">w</span>
</pre></div>
</div>
</div>
<p>We are interested in polling strategies that will help us predict <span class="math notranslate nohighlight">\(w\)</span>, rather than predicting the more complex state-by-state results <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<p>To set up a fully Bayesian model, we need a prior for <span class="math notranslate nohighlight">\(\alpha\)</span>. We will base the prior on the outcome of some historical presidential elections. Specifically, we’ll use the following dataset of state-by-state election results for the presidential elections 1976-2012 inclusive. Note that votes for parties other than Democrats and Republicans have been ignored.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">urlopen</span><span class="p">(</span><span class="n">BASE_URL</span> <span class="o">+</span> <span class="s2">&quot;us_presidential_election_data_historical.pickle&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">frame</span><span class="p">[[</span><span class="mi">1976</span><span class="p">,</span> <span class="mi">1980</span><span class="p">,</span> <span class="mi">1984</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
          1976                1980                1984
      Democrat Republican Democrat Republican Democrat Republican
State
AL      659170     504070   636730     654192   551899     872849
AK       44058      71555    41842      86112    62007     138377
AZ      295602     418642   246843     529688   333854     681416
AR      499614     268753   398041     403164   338646     534774
CA     3742284    3882244  3083661    4524858  3922519    5467009
</pre></div></div>
</div>
<p>Based on this data alone, we will base our prior mean for <span class="math notranslate nohighlight">\(\alpha\)</span> solely on the 2012 election. Our model will be based on logistic regression, so we will transform the probability of voting Democrat using the logit function. Specifically, we’ll choose a prior mean as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">results_2012</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">frame</span><span class="p">[</span><span class="mi">2012</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">prior_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">results_2012</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">results_2012</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>Our prior distribution for <span class="math notranslate nohighlight">\(\alpha\)</span> will be a multivariate Normal with mean <code class="docutils literal notranslate"><span class="pre">prior_mean</span></code>. The only thing left to decide upon is the covariance matrix. Since <code class="docutils literal notranslate"><span class="pre">alpha</span></code> values are logit-transformed, the covariance will be defined in logit space as well.</p>
<p><em>Aside</em>: The prior covariance is important in a number of ways. If we allow too much variance, the prior will be uncertain about the outcome in every state, and require polling everywhere. If we allow too little variance, we may be caught off-guard by an unexpected electoral outcome. If we assume states are independent, then we will not be able to pool information across states; but assume too much correlation and we could too faithfully base predictions about one state from poll results in
another.</p>
<p>We select the prior covariance by taking the empirical covariance from the elections 1976 - 2012 and adding a small value <code class="docutils literal notranslate"><span class="pre">0.01</span></code> to the diagonal.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">idx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">as_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">as_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">/</span> <span class="n">as_tensor</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sample_covariance</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prior_covariance</span> <span class="o">=</span> <span class="n">sample_covariance</span> <span class="o">+</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">sample_covariance</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Setting-up-the-model">
<h2>Setting up the model<a class="headerlink" href="#Setting-up-the-model" title="Permalink to this headline">¶</a></h2>
<p>We are now in a position to define our model. At a high-level the model works as follows: - <span class="math notranslate nohighlight">\(\alpha\)</span> is multivariate Normal - <span class="math notranslate nohighlight">\(w\)</span> is a deterministic function of <span class="math notranslate nohighlight">\(\alpha\)</span> - <span class="math notranslate nohighlight">\(y_i\)</span> is Binomial(<span class="math notranslate nohighlight">\(n_i\)</span>, sigmoid(<span class="math notranslate nohighlight">\(\alpha_i\)</span>)) so we are assuming that people respond to the poll in exactly the same way that they will vote on election day</p>
<p>In Pyro, this model looks as follows</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">import</span> <span class="nn">pyro.distributions</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">polling_allocation</span><span class="p">):</span>
    <span class="c1"># This allows us to run many copies of the model in parallel</span>
    <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate_stack</span><span class="p">(</span><span class="s2">&quot;plate_stack&quot;</span><span class="p">,</span> <span class="n">polling_allocation</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="c1"># Begin by sampling alpha</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
            <span class="n">prior_mean</span><span class="p">,</span> <span class="n">covariance_matrix</span><span class="o">=</span><span class="n">prior_covariance</span><span class="p">))</span>

        <span class="c1"># Sample y conditional on alpha</span>
        <span class="n">poll_results</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span>
            <span class="n">polling_allocation</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Now compute w according to the (approximate) electoral college formula</span>
        <span class="n">dem_win</span> <span class="o">=</span> <span class="n">election_winner</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Delta</span><span class="p">(</span><span class="n">dem_win</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">poll_results</span><span class="p">,</span> <span class="n">dem_win</span><span class="p">,</span> <span class="n">alpha</span>
</pre></div>
</div>
</div>
<div class="section" id="Understanding-the-prior">
<h3>Understanding the prior<a class="headerlink" href="#Understanding-the-prior" title="Permalink to this headline">¶</a></h3>
<p>Before we go any further, we’re going to study the model to check it matches with our intuition about US presidential elections.</p>
<p>First of all, let’s look at an upper and lower confidence limit for the proportion of voters who will vote Democrat in each state.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">std</span> <span class="o">=</span> <span class="n">prior_covariance</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<span class="n">ci</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;State&quot;</span><span class="p">:</span> <span class="n">frame</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                   <span class="s2">&quot;Lower confidence limit&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">prior_mean</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">std</span><span class="p">),</span>
                   <span class="s2">&quot;Upper confidence limit&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">prior_mean</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">std</span><span class="p">)}</span>
                 <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;State&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ci</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
       Lower confidence limit  Upper confidence limit
State
AL                   0.272258                0.517586
AK                   0.330472                0.529117
AZ                   0.321011                0.593634
AR                   0.214348                0.576079
CA                   0.458618                0.756616
</pre></div></div>
</div>
<p>The prior on <span class="math notranslate nohighlight">\(\alpha\)</span> implicitly defines our prior on <code class="docutils literal notranslate"><span class="pre">w</span></code>. We can investigate this prior by simulating many times from the prior.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">_</span><span class="p">,</span> <span class="n">dem_wins</span><span class="p">,</span> <span class="n">alpha_samples</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100000</span><span class="p">,</span> <span class="mi">51</span><span class="p">))</span>
<span class="n">prior_w_prob</span> <span class="o">=</span> <span class="n">dem_wins</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prior probability of Dem win&quot;</span><span class="p">,</span> <span class="n">prior_w_prob</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prior probability of Dem win 0.6799200177192688
</pre></div></div>
</div>
<p>Since our prior is based on 2012 and the Democrats won in 2012, it makes sense that we would favour a Democrat win in 2016 (this is before we have seen <em>any</em> polling data or incorporated any other information).</p>
<p>We can also investigate which states, a priori, are most marginal.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">dem_prob</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_samples</span> <span class="o">&gt;</span> <span class="mf">0.</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">marginal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">((</span><span class="n">dem_prob</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">prior_prob_dem</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;State&quot;</span><span class="p">:</span> <span class="n">frame</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">marginal</span><span class="p">],</span>
                               <span class="s2">&quot;Democrat win probability&quot;</span><span class="p">:</span> <span class="n">dem_prob</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="n">marginal</span><span class="p">]}</span>
                             <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;State&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prior_prob_dem</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
       Democrat win probability
State
FL                      0.52501
NC                      0.42730
NH                      0.61536
OH                      0.61997
VA                      0.63738
</pre></div></div>
</div>
<p>This is a sanity check, and seems to accord with our intuitions. Florida is frequently an important swing state and is top of our list of marginal states under the prior. We can also see states such as Pennsylvania and Wisconsin near the top of the list – we know that these were instrumental in the 2016 election.</p>
<p>Finally, we take a closer look at our prior covariance. Specifically, we examine states that we expect to be more or less correlated. Let’s begin by looking at states in New England</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">correlation</span><span class="p">(</span><span class="n">cov</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cov</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="o">.</span><span class="n">values</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>


<span class="n">new_england_states</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ME&#39;</span><span class="p">,</span> <span class="s1">&#39;VT&#39;</span><span class="p">,</span> <span class="s1">&#39;NH&#39;</span><span class="p">,</span> <span class="s1">&#39;MA&#39;</span><span class="p">,</span> <span class="s1">&#39;RI&#39;</span><span class="p">,</span> <span class="s1">&#39;CT&#39;</span><span class="p">]</span>
<span class="n">cov_as_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">prior_covariance</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">frame</span><span class="o">.</span><span class="n">index</span><span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">ne_cov</span> <span class="o">=</span> <span class="n">cov_as_frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">new_england_states</span><span class="p">,</span> <span class="n">new_england_states</span><span class="p">]</span>
<span class="n">ne_corr</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">ne_cov</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ne_corr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
State        ME        VT        NH        MA        RI        CT
State
ME     1.000000  0.817323  0.857351  0.800276  0.822024  0.825383
VT     0.817323  1.000000  0.834723  0.716342  0.754026  0.844140
NH     0.857351  0.834723  1.000000  0.871370  0.803803  0.873496
MA     0.800276  0.716342  0.871370  1.000000  0.813665  0.835148
RI     0.822024  0.754026  0.803803  0.813665  1.000000  0.849644
CT     0.825383  0.844140  0.873496  0.835148  0.849644  1.000000
</pre></div></div>
</div>
<p>Clearly, these states tend to vote similarly. We can also examine some states of the South which we also expect to be similar.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">southern_states</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LA&#39;</span><span class="p">,</span> <span class="s1">&#39;MS&#39;</span><span class="p">,</span> <span class="s1">&#39;AL&#39;</span><span class="p">,</span> <span class="s1">&#39;GA&#39;</span><span class="p">,</span> <span class="s1">&#39;SC&#39;</span><span class="p">]</span>
<span class="n">southern_cov</span> <span class="o">=</span> <span class="n">cov_as_frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">southern_states</span><span class="p">,</span> <span class="n">southern_states</span><span class="p">]</span>
<span class="n">southern_corr</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">southern_cov</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">southern_corr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
State        LA        MS        AL        GA        SC
State
LA     1.000000  0.554020  0.651511  0.523784  0.517672
MS     0.554020  1.000000  0.699459  0.784371  0.769198
AL     0.651511  0.699459  1.000000  0.829908  0.723015
GA     0.523784  0.784371  0.829908  1.000000  0.852818
SC     0.517672  0.769199  0.723015  0.852818  1.000000
</pre></div></div>
</div>
<p>These correlation matrices show that, as expected, logical groupings of states tend to have similar voting trends. We now look at the correlations <em>between</em> the groups (e.g. between Maine and Louisiana).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cross_cov</span> <span class="o">=</span> <span class="n">cov_as_frame</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">new_england_states</span> <span class="o">+</span> <span class="n">southern_states</span><span class="p">,</span> <span class="n">new_england_states</span> <span class="o">+</span> <span class="n">southern_states</span><span class="p">]</span>
<span class="n">cross_corr</span> <span class="o">=</span> <span class="n">correlation</span><span class="p">(</span><span class="n">cross_cov</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cross_corr</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">new_england_states</span><span class="p">,</span> <span class="n">southern_states</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
State        LA        MS        AL        GA        SC
State
ME     0.329438  0.309352 -0.000534  0.122375  0.333679
VT    -0.036079  0.009653 -0.366604 -0.202065  0.034438
NH     0.234105  0.146826 -0.105781  0.008411  0.233084
MA     0.338411  0.122257 -0.059107 -0.025730  0.182290
RI     0.314088  0.188819 -0.066307 -0.022142  0.186955
CT     0.139021  0.074646 -0.205797 -0.107684  0.125023
</pre></div></div>
</div>
<p>Now, we see weaker correlation between New England states and Southern states than the correlation within those grouping. Again, this is as expected.</p>
</div>
</div>
<div class="section" id="Measuring-the-expected-information-gain-of-a-polling-strategy">
<h2>Measuring the expected information gain of a polling strategy<a class="headerlink" href="#Measuring-the-expected-information-gain-of-a-polling-strategy" title="Permalink to this headline">¶</a></h2>
<p>The prior we have set up appears to accord, at least approximately, with intuition. However, we now want to add a second source of information from polling. We aim to use our prior to select a polling strategy that will be most informative about our target <span class="math notranslate nohighlight">\(w\)</span>. A polling strategy, in this simplified set-up, is the number of people to poll in each state. (We ignore any other covariates such as regional variation inside states, demographics, etc.) We might imagine that polling 1000 people in
Florida (the most marginal state), will be much more effective than polling 1000 people in DC (the least marginal state). That’s because the outcome in DC is already quite predictable, just based on our prior, whereas the outcome in Florida is really up for grabs.</p>
<p>In fact, the information that our model will gain about <span class="math notranslate nohighlight">\(w\)</span> based on conducting a poll with design <span class="math notranslate nohighlight">\(d\)</span> and getting outcome <span class="math notranslate nohighlight">\(y\)</span> can be described mathematically as follows:</p>
<div class="math notranslate nohighlight">
\[\text{IG}(d, y) = KL(p(w|y,d)||p(w)).\]</div>
<p>Since the outcome of the poll is at present unknown, we consider the expected information gain [1]</p>
<div class="math notranslate nohighlight">
\[\text{EIG}(d) = \mathbb{E}_{p(y|d)}[KL(p(w|y,d)||p(w))].\]</div>
<div class="section" id="Variational-estimators-of-EIG">
<h3>Variational estimators of EIG<a class="headerlink" href="#Variational-estimators-of-EIG" title="Permalink to this headline">¶</a></h3>
<p>In the <a class="reference external" href="http://pyro.ai/examples/working_memory.html">working memory tutorial</a>, we used the ‘marginal’ estimator to find the EIG. This involved estimating the marginal density <span class="math notranslate nohighlight">\(p(y|d)\)</span>. In this experiment, that would be relatively difficult: <span class="math notranslate nohighlight">\(y\)</span> is 51-dimensional with some rather tricky constraints that make modelling its density difficult. Furthermore, the marginal estimator requires us to know <span class="math notranslate nohighlight">\(p(y|w)\)</span> analytically, which we do not.</p>
<p>Fortunately, other variational estimators of EIG exist: see [2] for more details. One such variational estimator is the ‘posterior’ estimator, based on the following representation</p>
<div class="math notranslate nohighlight">
\[\text{EIG}(d) = \max_q \mathbb{E}_{p(w, y|d)}\left[\log q(w|y) \right] + H(p(w)).\]</div>
<p>Here, <span class="math notranslate nohighlight">\(H(p(w))\)</span> is the prior entropy on <span class="math notranslate nohighlight">\(w\)</span> (we can compute this quite easily). The important term involves the variational approximation <span class="math notranslate nohighlight">\(q(w|y)\)</span>. This <span class="math notranslate nohighlight">\(q\)</span> can be used to perform amortized variational inference. Specifically, it takes as input <span class="math notranslate nohighlight">\(y\)</span> and outputs a distribution over <span class="math notranslate nohighlight">\(w\)</span>. The bound is maximised when <span class="math notranslate nohighlight">\(q(w|y) = p(w|y)\)</span> [2]. Since <span class="math notranslate nohighlight">\(w\)</span> is a binary random variable, we can think of <span class="math notranslate nohighlight">\(q\)</span> as a classifier that tries to decide, based on the
poll outcome, who the eventual winner of the election will be. In this notebook, <span class="math notranslate nohighlight">\(q\)</span> will be a neural classifier. Training a neural classifier is a fair bit easier than learning the marginal density of <span class="math notranslate nohighlight">\(y\)</span>, so we adopt this method to estimate the EIG in this tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">OutcomePredictor</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_dem_probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h1</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h2</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">h3</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_dict</span><span class="p">,</span> <span class="n">design</span><span class="p">,</span> <span class="n">observation_labels</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">):</span>

        <span class="n">pyro</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="s2">&quot;posterior_guide&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">y_dict</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
        <span class="n">dem_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dem_probability</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">dem_prob</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>We’ll now use this to compute the EIG for several possible polling strategies. First, we need to compute the <span class="math notranslate nohighlight">\(H(p(w))\)</span> term in the above formula.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">prior_entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">prior_w_prob</span><span class="p">)</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Let’s consider four simple polling strategies. 1. Poll 1000 people in Florida only 2. Poll 1000 people in DC only 3. Poll 1000 people spread evenly over the US 4. Using a polling allocation that focuses on swing states</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>

<span class="n">poll_in_florida</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">51</span><span class="p">)</span>
<span class="n">poll_in_florida</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">poll_in_dc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">51</span><span class="p">)</span>
<span class="n">poll_in_dc</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">uniform_poll</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span> <span class="o">//</span> <span class="mi">51</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">51</span><span class="p">)</span>

<span class="c1"># The swing score measures how close the state is to 50/50</span>
<span class="n">swing_score</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="o">.</span><span class="mi">5</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">prior_prob_dem</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;State&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span>
<span class="n">swing_poll</span> <span class="o">=</span> <span class="mi">1000</span> <span class="o">*</span> <span class="n">swing_score</span> <span class="o">/</span> <span class="n">swing_score</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">swing_poll</span> <span class="o">=</span> <span class="n">swing_poll</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="n">poll_strategies</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="s2">&quot;Florida&quot;</span><span class="p">,</span> <span class="n">poll_in_florida</span><span class="p">),</span>
                               <span class="p">(</span><span class="s2">&quot;DC&quot;</span><span class="p">,</span> <span class="n">poll_in_dc</span><span class="p">),</span>
                               <span class="p">(</span><span class="s2">&quot;Uniform&quot;</span><span class="p">,</span> <span class="n">uniform_poll</span><span class="p">),</span>
                               <span class="p">(</span><span class="s2">&quot;Swing&quot;</span><span class="p">,</span> <span class="n">swing_poll</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<p>We’ll now compute the EIG for each option. Since this requires training the network (four times) it may take several minutes.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">pyro.contrib.oed.eig</span> <span class="k">import</span> <span class="n">posterior_eig</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="k">import</span> <span class="n">Adam</span>

<span class="n">eigs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">best_strategy</span><span class="p">,</span> <span class="n">best_eig</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">strategy</span><span class="p">,</span> <span class="n">allocation</span> <span class="ow">in</span> <span class="n">poll_strategies</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">strategy</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">guide</span> <span class="o">=</span> <span class="n">OutcomePredictor</span><span class="p">()</span>
    <span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
    <span class="c1"># To reduce noise when comparing designs, we will use the precomputed value of H(p(w))</span>
    <span class="c1"># By passing eig=False, we tell Pyro not to estimate the prior entropy on each run</span>
    <span class="c1"># The return value of `posterior_eig` is then -E_p(w,y)[log q(w|y)]</span>
    <span class="n">ape</span> <span class="o">=</span> <span class="n">posterior_eig</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">allocation</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12500</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span>
                        <span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}),</span> <span class="n">eig</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">final_num_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
    <span class="n">eigs</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span> <span class="o">=</span> <span class="n">prior_entropy</span> <span class="o">-</span> <span class="n">ape</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">eigs</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">eigs</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">best_eig</span><span class="p">:</span>
        <span class="n">best_strategy</span><span class="p">,</span> <span class="n">best_eig</span> <span class="o">=</span> <span class="n">strategy</span><span class="p">,</span> <span class="n">eigs</span><span class="p">[</span><span class="n">strategy</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Florida 0.3088182508945465
DC 0.000973820686340332
Uniform 0.30316317081451416
Swing 0.3254041075706482
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Running-the-experiment">
<h2>Running the experiment<a class="headerlink" href="#Running-the-experiment" title="Permalink to this headline">¶</a></h2>
<p>We have now scored our four candidate designs and can choose the best one to use to actually gather new data. In this notebook, we will simulate the new data using the results from the 2016 election. Specifically, we will assume that the outcome of the poll comes from our model, where we condition the value of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> to correspond to the actual results in 2016.</p>
<p>First, we retrain <span class="math notranslate nohighlight">\(q\)</span> with the chosen polling strategy.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">best_allocation</span> <span class="o">=</span> <span class="n">poll_strategies</span><span class="p">[</span><span class="n">best_strategy</span><span class="p">]</span>
<span class="n">pyro</span><span class="o">.</span><span class="n">clear_param_store</span><span class="p">()</span>
<span class="n">guide</span> <span class="o">=</span> <span class="n">OutcomePredictor</span><span class="p">()</span>
<span class="n">posterior_eig</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">best_allocation</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12500</span><span class="p">,</span> <span class="n">guide</span><span class="p">,</span>
              <span class="n">Adam</span><span class="p">({</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">}),</span> <span class="n">eig</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(0.3653, grad_fn=&lt;DivBackward0&gt;)
</pre></div></div>
</div>
<p>The value of <span class="math notranslate nohighlight">\(\alpha\)</span> implied by the 2016 results is computed in the same way we computed the prior.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">urlopen</span><span class="p">(</span><span class="n">BASE_URL</span> <span class="o">+</span> <span class="s2">&quot;us_presidential_election_data_test.pickle&quot;</span><span class="p">))</span>
<span class="n">results_2016</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">true_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">results_2016</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">results_2016</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">conditioned_model</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">condition</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">true_alpha</span><span class="p">})</span>
<span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conditioned_model</span><span class="p">(</span><span class="n">best_allocation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s view the outcome of our poll.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">outcome</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&quot;State&quot;</span><span class="p">:</span> <span class="n">frame</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                        <span class="s2">&quot;Number of people polled&quot;</span><span class="p">:</span> <span class="n">best_allocation</span><span class="p">,</span>
                        <span class="s2">&quot;Number who said they would vote Democrat&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
                      <span class="p">)</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;State&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outcome</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s2">&quot;Number of people polled&quot;</span><span class="p">,</span> <span class="s2">&quot;State&quot;</span><span class="p">],</span> <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
       Number of people polled  Number who said they would vote Democrat
State
FL                       191.0                                      89.0
NE                        66.0                                      30.0
NJ                        41.0                                      22.0
OH                        40.0                                      19.0
VT                        35.0                                      22.0
</pre></div></div>
</div>
<div class="section" id="Analysing-the-data">
<h3>Analysing the data<a class="headerlink" href="#Analysing-the-data" title="Permalink to this headline">¶</a></h3>
<p>Having collected our data, we can now perform inference under our model to obtain the posterior probability of a Democrat win. There are many ways to perform the inference: for instance we could use variational inference with Pyro’s <code class="docutils literal notranslate"><span class="pre">SVI</span></code> or MCMC such as Pyro’s <code class="docutils literal notranslate"><span class="pre">NUTS</span></code>. Using these methods, we would compute the posterior over <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, and use this to obtain the posterior over <code class="docutils literal notranslate"><span class="pre">w</span></code>.</p>
<p>However, a quick way to analyze the data is to use the neural network we have already trained. At convergence, we expect the network to give a good approximation to the true posterior, i.e. <span class="math notranslate nohighlight">\(q(w|y) \approx p(w|y)\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">q_w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">guide</span><span class="o">.</span><span class="n">compute_dem_probability</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prior probability of Democrat win&quot;</span><span class="p">,</span> <span class="n">prior_w_prob</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Posterior probability of Democrat win&quot;</span><span class="p">,</span> <span class="n">q_w</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prior probability of Democrat win 0.6799200177192688
Posterior probability of Democrat win 0.40527692437171936
</pre></div></div>
</div>
<p>This completes the whole process of experimental design, obtaining data, and data analysis. By using our analysis model and prior to design the polling strategy, we were able to choose the design that led to the greatest expected gain in information.</p>
</div>
</div>
<div class="section" id="Conclusions">
<h2>Conclusions<a class="headerlink" href="#Conclusions" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we showed how optimal experimental design principles can be applied to electoral polling. If we have the option of first designing the polling strategy using our prior, this can help lead to better predictions once we have collected our data.</p>
<p>Our model could be enhanced in a number of ways: a useful guide to the kinds of models used in political science can be found in [3]. Our optimal design strategy will only ever be as good as our prior, so there is certainly a lot of use in investing time in choosing a good prior.</p>
<p>It might also be possible to search over the possible polling strategies in a more sophisticated way. For instance, simulated annealing [4] is one technique that can be used for optimization in high-dimensional discrete spaces.</p>
<p>Our polling strategies were chosen with one objective in mind: predict the final outcome <span class="math notranslate nohighlight">\(w\)</span>. If, on the other hand, we wanted to make more fine-grained predictions, we could use the same procedure but treat <span class="math notranslate nohighlight">\(\alpha\)</span> as our target instead of <span class="math notranslate nohighlight">\(w\)</span>.</p>
<p>Finally, it’s worth noting that there is a connection to Bayesian model selection: specifically, in a different model we might have <span class="math notranslate nohighlight">\(w\)</span> a binary random variable to choose between different sub-models. Although conceptually different, our election set-up and the model selection set-up share many mathematical features which means that a similar experimental design approach could be used in both cases.</p>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[1] Chaloner, K. and Verdinelli, I., 1995. <strong>Bayesian experimental design: A review.</strong> Statistical Science, pp.273-304.</p>
<p>[2] Foster, A., Jankowiak, M., Bingham, E., Horsfall, P., Teh, Y.W., Rainforth, T. and Goodman, N., 2019. <strong>Variational Bayesian Optimal Experimental Design.</strong> Advances in Neural Information Processing Systems 2019 (to appear).</p>
<p>[3] Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A. and Rubin, D.B., 2013. <strong>Bayesian data analysis.</strong> Chapman and Hall/CRC.</p>
<p>[4] Kirkpatrick, S., Gelatt, C.D. and Vecchi, M.P., 1983. <strong>Optimization by simulated annealing.</strong> Science, 220(4598), pp.671-680.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dirichlet_process_mixture.html" class="btn btn-neutral float-right" title="Dirichlet Process Mixture Models in Pyro" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="working_memory.html" class="btn btn-neutral float-left" title="Designing Adaptive Experiments to Study Working Memory" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright Uber Technologies, Inc; 编译 by Heyang Gong

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>